{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97183045",
   "metadata": {},
   "source": [
    "# Create and run a local RAG pipeline from scratch\n",
    "\n",
    "The goal of this notebook is to build a RAG (Retrieval Augmented Generation) pipeline from scratch and have it run on a local GPU.\n",
    "\n",
    "Specifically, we'd like to be able to open a PDF file, ask questions (queries) of it and have them answered by a Large Language Model (LLM).\n",
    "\n",
    "There are frameworks that replicate this kind of workflow, including [LlamaIndex](https://www.llamaindex.ai/) and [LangChain](https://www.langchain.com/), however, the goal of building from scratch is to be able to inspect and customize all the parts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c672248d",
   "metadata": {},
   "source": [
    "## What is RAG?\n",
    "\n",
    "RAG stands for Retrieval Augmented Generation.\n",
    "\n",
    "Each step can be roughly broken down to:\n",
    "\n",
    "* **Retrieval** - Seeking relevant information from a source given a query. For example, getting relevant passages of Wikipedia text from a database given a question.\n",
    "* **Augmented** - Using the relevant retrieved information to modify an input to a generative model (e.g. an LLM).\n",
    "* **Generation** - Generating an output given an input. For example, in the case of an LLM, generating a passage of text given an input prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f661ce",
   "metadata": {},
   "source": [
    "## Why RAG?\n",
    "\n",
    "The main goal of RAG is to improve the generation outputs of LLMs.\n",
    "\n",
    "Two primary improvements can be seen as:\n",
    "1. **Preventing \"hallucinations\"** - LLMs are incredible but they are prone to potential hallucination, as in, generating something that *looks* correct but isn't. RAG pipelines can help LLMs generate more factual outputs by providing them with factual (retrieved) inputs. And even if the generated answer from a RAG pipeline doesn't seem correct, because of retrieval, you also have access to the sources where it came from.\n",
    "2. **Work with custom data** - Many base LLMs are trained with internet-scale text data. This means they have a great ability to model language, however, they often lack specific knowledge. RAG systems can provide LLMs with domain-specific data such as medical information or company documentation and thus customized their outputs to suit specific use cases.\n",
    "\n",
    "RAG can also be a much quicker solution to implement than fine-tuning an LLM on specific data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99365f0f",
   "metadata": {},
   "source": [
    "\n",
    "## What kind of problems can RAG be used for?\n",
    "\n",
    "RAG can help anywhere there is a specific set of information that an LLM may not have in its training data (e.g. anything not publicly accessible on the internet).\n",
    "\n",
    "For example you could use RAG for:\n",
    "* **Customer support Q&A chat** - By treating your existing customer support documentation as a resource, when a customer asks a question, you could have a system retrieve relevant documentation snippets and then have an LLM craft those snippets into an answer. Think of this as a \"chatbot for your documentation\". Klarna, a large financial company, [uses a system like this](https://www.klarna.com/international/press/klarna-ai-assistant-handles-two-thirds-of-customer-service-chats-in-its-first-month/) to save $40M per year on customer support costs.\n",
    "* **Email chain analysis** - Let's say you're an insurance company with long threads of emails between customers and insurance agents. Instead of searching through each individual email, you could retrieve relevant passages and have an LLM create strucutred outputs of insurance claims.\n",
    "* **Company internal documentation chat** - If you've worked at a large company, you know how hard it can be to get an answer sometimes. Why not let a RAG system index your company information and have an LLM answer questions you may have? The benefit of RAG is that you will have references to resources to learn more if the LLM answer doesn't suffice.\n",
    "* **Textbook Q&A** - Let's say you're studying for your exams and constantly flicking through a large textbook looking for answers to your quesitons. RAG can help provide answers as well as references to learn more. (we will try to implement this)\n",
    "\n",
    "All of these have the common theme of retrieving relevant resources and then presenting them in an understandable way using an LLM.\n",
    "\n",
    "From this angle, you can consider an LLM a calculator for words.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74729450",
   "metadata": {},
   "source": [
    "## Why local?\n",
    "\n",
    "Privacy, speed, cost.\n",
    "\n",
    "Running locally means you use your own hardware.\n",
    "\n",
    "From a privacy standpoint, this means you don't have send potentially sensitive data to an API.\n",
    "\n",
    "From a speed standpoint, it means you won't necessarily have to wait for an API queue or downtime, if your hardware is running, the pipeline can run.\n",
    "\n",
    "And from a cost standpoint, running on your own hardware often has a heavier starting cost but little to no costs after that.\n",
    "\n",
    "Performance wise, LLM APIs may still perform better than an open-source model running locally on general tasks but there are more and more examples appearing of smaller, focused models outperforming larger models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7a1a11",
   "metadata": {},
   "source": [
    "## Key terms\n",
    "\n",
    "| Term | Description |\n",
    "| ----- | ----- | \n",
    "| **Token** | A sub-word piece of text. For example, \"hello, world!\" could be split into [\"hello\", \",\", \"world\", \"!\"]. A token can be a whole word, part of a word or group of punctuation characters. 1 token ~= 4 characters in English, 100 tokens ~= 75 words.<br> Text gets broken into tokens before being passed to an LLM. |\n",
    "| **Embedding** | A learned numerical representation of a piece of data. For example, a sentence of text could be represented by a vector with<br> 768 values. Similar pieces of text (in meaning) will ideally have similar values. |\n",
    "| **Embedding model** | A model designed to accept input data and output a numerical representation. For example, a text embedding model may take in 384 tokens of text and turn it into a vector of size 768. An embedding model can and often is different to an LLM model. |\n",
    "| **Similarity search/vector search** | Similarity search/vector search aims to find two vectors which are close together in high-demensional space. For example, two pieces of similar text passed through an embedding model should have a high similarity score, whereas two pieces of text about different topics will have a lower similarity score. Common similarity score measures are dot product and cosine similarity. |\n",
    "| **Large Language Model (LLM)** | A model which has been trained to numerically represent the patterns in text. A generative LLM will continue a sequence when given a sequence. For example, given a sequence of the text \"hello, world!\", a genertive LLM may produce \"we're going to build a RAG pipeline today!\". This generation will be highly dependant on the training data and prompt. |\n",
    "| **LLM context window** | The number of tokens a LLM can accept as input. For example, as of March 2024, GPT-4 has a default context window of 32k tokens (about 96 pages of text) but can go up to 128k if needed. A recent open-source LLM from Google, Gemma (March 2024) has a context window of 8,192 tokens (about 24 pages of text). A higher context window means an LLM can accept more relevant information to assist with a query. For example, in a RAG pipeline, if a model has a larger context window, it can accept more reference items from the retrieval system to aid with its generation. |\n",
    "| **Prompt** | A common term for describing the input to a generative LLM. The idea of prompt engineering is to structure a text-based (or potentially image-based as well) input to a generative LLM in a specific way so that the generated output is ideal. This technique is possible because of a LLMs capacity for in-context learning, as in, it is able to use its representation of language to breakdown the prompt and recognize what a suitable output may be (note: the output of LLMs is probable, so terms like \"may output\" are used). | \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b06606",
   "metadata": {},
   "source": [
    " ## What we're going to build\n",
    "\n",
    "We're going to build RAG pipeline which enables us to chat with a PDF document, specifically an open-source [nutrition textbook](https://pressbooks.oer.hawaii.edu/humannutrition2/), ~1200 pages long.\n",
    "\n",
    "You could call our project NutriChat!\n",
    "\n",
    "We'll write the code to:\n",
    "1. Open a PDF document (you could use almost any PDF here).\n",
    "2. Format the text of the PDF textbook ready for an embedding model (this process is known as text splitting/chunking).\n",
    "3. Embed all of the chunks of text in the textbook and turn them into numerical representation which we can store for later.\n",
    "4. Build a retrieval system that uses vector search to find relevant chunks of text based on a query.\n",
    "5. Create a prompt that incorporates the retrieved pieces of text.\n",
    "6. Generate an answer to a query based on passages from the textbook.\n",
    "\n",
    "The above steps can broken down into two major sections:\n",
    "1. Document preprocessing/embedding creation (steps 1-3).\n",
    "2. Search and answer (steps 4-6).\n",
    "\n",
    "And that's the structure we'll follow.\n",
    "\n",
    "It's similar to the workflow outlined on the NVIDIA blog which [details a local RAG pipeline](https://developer.nvidia.com/blog/rag-101-demystifying-retrieval-augmented-generation-pipelines/).\n",
    "\n",
    "<img src=\"https://github.com/mrdbourke/simple-local-rag/blob/main/images/simple-local-rag-workflow-flowchart.png?raw=true\" alt=\"flowchart of a local RAG workflow\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc64c9c9",
   "metadata": {},
   "source": [
    "## Requirements and setup\n",
    "\n",
    "* Local NVIDIA GPU\n",
    "* Environment setup \n",
    "* Data source (for example, a PDF). \n",
    "* Internet connection (to download the models, but once you have them, it'll run offline)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47dbfc29",
   "metadata": {},
   "source": [
    "## 1. Document/Text Processing and Embedding Creation\n",
    "\n",
    "Ingredients:\n",
    "* PDF document of choice.\n",
    "* Embedding model of choice.\n",
    "\n",
    "Steps:\n",
    "1. Import PDF document.\n",
    "2. Process text for embedding (e.g. split into chunks of sentences).\n",
    "3. Embed text chunks with embedding model.\n",
    "4. Save embeddings to file for later use (embeddings will store on file for many years or until you lose your hard drive)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede2e0b",
   "metadata": {},
   "source": [
    "### Import PDF Document \n",
    "\n",
    "This will work with many other kinds of documents.\n",
    "\n",
    "However, we'll start with PDF since many people have PDFs.\n",
    "\n",
    "But just keep in mind, text files, email chains, support documentation, articles and more can also work.\n",
    "\n",
    "We're going to pretend we're nutrition students at the University of Hawai'i, reading through the open-source PDF textbook [*Human Nutrition: 2020 Edition*](https://pressbooks.oer.hawaii.edu/humannutrition2/).\n",
    "\n",
    "There are several libraries to open PDFs with Python but I found that [PyMuPDF](https://github.com/pymupdf/pymupdf) works quite well in many cases.\n",
    "\n",
    "First we'll download the PDF if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ce88c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File human-nutrition-text.pdf exists.\n"
     ]
    }
   ],
   "source": [
    "# Download PDF file\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Get PDF document\n",
    "pdf_path = \"human-nutrition-text.pdf\"\n",
    "\n",
    "# Download PDF if it doesn't already exist\n",
    "if not os.path.exists(pdf_path):\n",
    "  print(\"File doesn't exist, downloading...\")\n",
    "\n",
    "  # The URL of the PDF you want to download\n",
    "  url = \"https://pressbooks.oer.hawaii.edu/humannutrition2/open/download?type=pdf\"\n",
    "\n",
    "  # The local filename to save the downloaded file\n",
    "  filename = pdf_path\n",
    "\n",
    "  # Send a GET request to the URL\n",
    "  response = requests.get(url)\n",
    "\n",
    "  # Check if the request was successful\n",
    "  if response.status_code == 200:\n",
    "      # Open a file in binary write mode and save the content to it\n",
    "      with open(filename, \"wb\") as file:\n",
    "          file.write(response.content)\n",
    "      print(f\"The file has been downloaded and saved as {filename}\")\n",
    "  else:\n",
    "      print(f\"Failed to download the file. Status code: {response.status_code}\")\n",
    "else:\n",
    "  print(f\"File {pdf_path} exists.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736707a7",
   "metadata": {},
   "source": [
    "PDF acquired!\n",
    "\n",
    "We can import the pages of our PDF to text by first defining the PDF path and then opening and reading it with PyMuPDF (`import fitz`).\n",
    "\n",
    "We'll write a small helper function to preprocess the text as it gets read. Note that not all text will be read in the same so keep this in mind for when you prepare your text.\n",
    "\n",
    "We'll save each page to a dictionary and then append that dictionary to a list for ease of use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22a6d5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e02b0443a4492c965abb88cccadf62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'page_number': -41,\n",
       "  'page_char_count': 29,\n",
       "  'page_word_count': 4,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 7.25,\n",
       "  'text': 'Human Nutrition: 2020 Edition'},\n",
       " {'page_number': -40,\n",
       "  'page_char_count': 0,\n",
       "  'page_word_count': 1,\n",
       "  'page_sentence_count_raw': 1,\n",
       "  'page_token_count': 0.0,\n",
       "  'text': ''}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fitz\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    \"\"\"Performs minor formatting on text.\"\"\"\n",
    "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
    "    return cleaned_text\n",
    "\n",
    "# Open PDF and get lines/pages\n",
    "# Note: this only focuses on text, rather than images/figures etc\n",
    "def open_and_read_pdf(pdf_path: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Opens a PDF file, reads its text content page by page, and collects statistics.\n",
    "\n",
    "    Parameters:\n",
    "        pdf_path (str): The file path to the PDF document to be opened and read.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dictionaries, each containing the page number\n",
    "        (adjusted), character count, word count, sentence count, token count, and the extracted text\n",
    "        for each page.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)  # open a document\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc)):  # iterate the document pages\n",
    "        text = page.get_text()  # get plain text encoded as UTF-8\n",
    "        text = text_formatter(text)\n",
    "        pages_and_texts.append({\"page_number\": page_number - 41,  # adjust page numbers since our PDF starts on page 42\n",
    "                                \"page_char_count\": len(text),\n",
    "                                \"page_word_count\": len(text.split(\" \")),\n",
    "                                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                                \"page_token_count\": len(text) / 4,  # 1 token = ~4 chars, see: https://help.openai.com/en/articles/4936856-what-are-tokens-and-how-to-count-them\n",
    "                                \"text\": text})\n",
    "    return pages_and_texts\n",
    "\n",
    "pages_and_texts = open_and_read_pdf(pdf_path=pdf_path)\n",
    "pages_and_texts[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f81973",
   "metadata": {},
   "source": [
    "Now let's get a random sample of the pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65677f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 1114,\n",
       "  'page_char_count': 1514,\n",
       "  'page_word_count': 235,\n",
       "  'page_sentence_count_raw': 17,\n",
       "  'page_token_count': 378.5,\n",
       "  'text': 'Prediabetes  As the term infers, prediabetes is a metabolic condition in which  people have moderately high glucose levels, but do not meet the  criteria for diagnosis as a diabetic. Over seventy-nine million  Americans are prediabetic and at increased risk for Type 2 diabetes  and cardiovascular disease.13 The National Diabetes Information  Clearing House reports that 35 percent of adults aged twenty and  older, and 50 percent of those over the age of sixty-five have  prediabetes.14  Long-Term Health Consequences of Diabetes  The long-term health consequences of diabetes are severe. They  are the result of chronically high glucose concentrations in the  blood accompanied by other metabolic abnormalities such as high  blood-lipid levels. People with diabetes are between two and four  times more likely to die from cardiovascular disease. Diabetes is  the number one cause of new cases of blindness, lower-limb  amputations, and kidney failure. Many people with diabetes develop  peripheral neuropathy, characterized by muscle weakness, loss of  feeling and pain in the lower extremities. More recently, there is  13. Diabetes Overview. National Institute of Diabetes and  Digestive and Kidney Disease.  https://www.niddk.nih.gov/health-information/ diabetes/overview. Accessed April 15, 2018.   14. Diabetes Overview. National Institute of Diabetes and  Digestive and Kidney Disease.  https://www.niddk.nih.gov/health-information/ diabetes/overview. Accessed April 15, 2018.   1114  |  Threats to Health'},\n",
       " {'page_number': 497,\n",
       "  'page_char_count': 778,\n",
       "  'page_word_count': 141,\n",
       "  'page_sentence_count_raw': 7,\n",
       "  'page_token_count': 194.5,\n",
       "  'text': 'Health Risks of Being Overweight and Being  Obese  The health consequences of obesity are great and contribute to  more than one hundred thousand deaths per year in the United  States. According to the CDC, in the United States in 2013-20146:  • 37.9% of adults age twenty years and over were obese  • 70.7% of adults age twenty years and over were overweight,  including obese  • 20.6% of adolescents age twelve to nineteen years were obese  • 17.4% of children age six to eleven years were obese  • 9.4% of children age two to five years were obese    6. Obesity and Overweight.The Centers for Disease Control  and Prevention. https://www.cdc.gov/nchs/fastats/ obesity-overweight.htm. Updated May 3, 2017. Accessed  June 19, 2017.  Factors Affecting Energy Expenditure  |  497'},\n",
       " {'page_number': 774,\n",
       "  'page_char_count': 1113,\n",
       "  'page_word_count': 197,\n",
       "  'page_sentence_count_raw': 7,\n",
       "  'page_token_count': 278.25,\n",
       "  'text': 'Instead of…  Replace with…  Sweetened fruit  yogurt  Plain fat-free yogurt with fresh fruit  Whole milk  Low-fat or fat-free milk  Cheese  Low-fat or reduced-fat cheese  Bacon or sausage Canadian bacon or lean ham  Sweetened  cereals  Minimally sweetened cereals with fresh fruit  Apple or berry  pie  Fresh apple or berries  Deep-fried  French fries  Oven-baked French fries or sweet potato baked fries  Fried vegetables  Steamed or roasted vegetables  Sugary  sweetened soft  drinks  Seltzer mixed with 100 percent fruit juice  Recipes that call  for sugar  Experiment with reducing amount of sugar and  adding spices (cinnamon, nutmeg, etc…)  Source:  Food  Groups.  US  Department  of  Agriculture.  http://www.choosemyplate.gov/food-groups/. Updated April 19,  2017. Accessed November 22, 2017.  Learning Activities  Technology Note: The second edition of the Human  Nutrition Open Educational Resource (OER) textbook  features interactive learning activities.  These activities are  available in the web-based textbook and not available in the  774  |  Understanding the Bigger Picture of Dietary Guidelines'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(pages_and_texts, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10590aa",
   "metadata": {},
   "source": [
    "### Get some stats on the text\n",
    "\n",
    "Let's perform a rough exploratory data analysis (EDA) to get an idea of the size of the texts (e.g. character counts, word counts etc) we're working with.\n",
    "\n",
    "The different sizes of texts will be a good indicator into how we should split our texts.\n",
    "\n",
    "Many embedding models have limits on the size of texts they can ingest, for example, the [`sentence-transformers`](https://www.sbert.net/docs/pretrained_models.html) model [`all-mpnet-base-v2`](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) has an input size of 384 tokens.\n",
    "\n",
    "This means that the model has been trained in ingest and turn into embeddings texts with 384 tokens (1 token ~= 4 characters ~= 0.75 words).\n",
    "\n",
    "Texts over 384 tokens which are encoded by this model will be auotmatically reduced to 384 tokens in length, potentially losing some information.\n",
    "\n",
    "We'll discuss this more in the embedding section.\n",
    "\n",
    "For now, let's turn our list of dictionaries into a DataFrame and explore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25e34667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-41</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7.25</td>\n",
       "      <td>Human Nutrition: 2020 Edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-39</td>\n",
       "      <td>320</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>80.00</td>\n",
       "      <td>Human Nutrition: 2020  Edition  UNIVERSITY OF ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-38</td>\n",
       "      <td>212</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>53.00</td>\n",
       "      <td>Human Nutrition: 2020 Edition by University of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-37</td>\n",
       "      <td>797</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "      <td>199.25</td>\n",
       "      <td>Contents  Preface  University of Hawai‘i at Mā...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0          -41               29                4                        1   \n",
       "1          -40                0                1                        1   \n",
       "2          -39              320               54                        1   \n",
       "3          -38              212               32                        1   \n",
       "4          -37              797              147                        3   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0              7.25                      Human Nutrition: 2020 Edition  \n",
       "1              0.00                                                     \n",
       "2             80.00  Human Nutrition: 2020  Edition  UNIVERSITY OF ...  \n",
       "3             53.00  Human Nutrition: 2020 Edition by University of...  \n",
       "4            199.25  Contents  Preface  University of Hawai‘i at Mā...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1d3f9ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>199.50</td>\n",
       "      <td>10.52</td>\n",
       "      <td>287.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.83</td>\n",
       "      <td>6.55</td>\n",
       "      <td>140.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>190.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>216.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>272.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>400.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>430.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>577.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1208.00          1208.00          1208.00                  1208.00   \n",
       "mean        562.50          1148.00           199.50                    10.52   \n",
       "std         348.86           560.38            95.83                     6.55   \n",
       "min         -41.00             0.00             1.00                     1.00   \n",
       "25%         260.75           762.00           134.00                     5.00   \n",
       "50%         562.50          1231.50           216.00                    10.00   \n",
       "75%         864.25          1603.50           272.00                    15.00   \n",
       "max        1166.00          2308.00           430.00                    39.00   \n",
       "\n",
       "       page_token_count  \n",
       "count           1208.00  \n",
       "mean             287.00  \n",
       "std              140.10  \n",
       "min                0.00  \n",
       "25%              190.50  \n",
       "50%              307.88  \n",
       "75%              400.88  \n",
       "max              577.00  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get stats\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae60f86",
   "metadata": {},
   "source": [
    "Okay, looks like our average token count per page is 287.\n",
    "\n",
    "For this particular use case, it means we could embed an average whole page with the `all-mpnet-base-v2` model (this model has an input capacity of 384)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5706da5d",
   "metadata": {},
   "source": [
    "### Further text processing (splitting pages into sentences)\n",
    "\n",
    "The ideal way of processing text before embedding it is still an active area of research.\n",
    "\n",
    "A simple method I've found helpful is to break the text into chunks of sentences.\n",
    "\n",
    "As in, chunk a page of text into groups of 5, 7, 10 or more sentences (these values are not set in stone and can be explored).\n",
    "\n",
    "But we want to follow the workflow of:\n",
    "\n",
    "`Ingest text -> split it into groups/chunks -> embed the groups/chunks -> use the embeddings`\n",
    "\n",
    "Some options for splitting text into sentences:\n",
    "\n",
    "1. Split into sentences with simple rules (e.g. split on \". \" with `text = text.split(\". \")`, like we did above).\n",
    "2. Split into sentences with a natural language processing (NLP) library such as [spaCy](https://spacy.io/) or [nltk](https://www.nltk.org/).\n",
    "\n",
    "Why split into sentences?\n",
    "\n",
    "* Easier to handle than larger pages of text (especially if pages are densely filled with text).\n",
    "* Can get specific and find out which group of sentences were used to help within a RAG pipeline.\n",
    "\n",
    "Let's use spaCy to break our text into sentences since it's likely a bit more robust than just using `text.split(\". \")`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4835b2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is a sentence., This is another sentence.]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "# Add a sentencizer pipeline, see https://spacy.io/api/sentencizer/ \n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "# Create a document instance as an example\n",
    "doc = nlp(\"This is a sentence. This is another sentence.\")\n",
    "assert len(list(doc.sents)) == 2\n",
    "\n",
    "# Access the sentences of the document\n",
    "list(doc.sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabfdd76",
   "metadata": {},
   "source": [
    "We don't necessarily need to use spaCy, however, it's an open-source library designed to do NLP tasks like this at scale.\n",
    "\n",
    "So let's run our small sentencizing pipeline on our pages of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15fc40a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2912cf47d544e3da67a44e433516410",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"]=list(nlp(item[\"text\"]).sents)\n",
    "\n",
    "    # Make sure all sentences are strings\n",
    "    item[\"sentences\"] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "    \n",
    "    # Count the sentences \n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d58c278b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 1056,\n",
       "  'page_char_count': 1545,\n",
       "  'page_word_count': 269,\n",
       "  'page_sentence_count_raw': 16,\n",
       "  'page_token_count': 386.25,\n",
       "  'text': 'butter on your toast, making your own salad dressing using  olive oil, vinegar or lemon juice, and herbs, cooking with  olive oil exclusively, or simply adding a dose of it to your  favorite meal.11  The Raw Food Diet  The raw food diet is followed by those who avoid cooking as much  as possible in order to take advantage of the full nutrient content  of foods. The principle behind raw foodism is that plant foods in  their natural state are the most wholesome for the body. The raw  food diet is not a weight-loss plan, it is a lifestyle choice. People who  practice raw foodism eat only uncooked and unprocessed foods,  emphasizing whole fruits and vegetables. Staples of the raw food  diet include whole grains, beans, dried fruits, seeds and nuts,  seaweed, sprouts, and unprocessed produce. As a result, food  preparation mostly involves peeling, chopping, blending, straining,  and dehydrating fruits and vegetables.  The positive aspects of this eating method include consuming  foods that are high in fiber and nutrients, and low in calories and  saturated fat. However, the raw food diet offers little in the way of  protein, dairy, or fats, which can cause deficiencies of the vitamins  A, D, E, and K. In addition, not all foods are healthier uncooked,  such as spinach and tomatoes. Also, cooking eliminates potentially  11. More Olive Oil in Diet Could Cut Stroke Risk: Study.  MedicineNet.com. https://www.medicinenet.com/ script/main/art.asp?articlekey=145823. Published 2011.  Accessed April 15,2018.  1056  |  Comparing Diets',\n",
       "  'sentences': ['butter on your toast, making your own salad dressing using  olive oil, vinegar or lemon juice, and herbs, cooking with  olive oil exclusively, or simply adding a dose of it to your  favorite meal.11  The Raw Food Diet  The raw food diet is followed by those who avoid cooking as much  as possible in order to take advantage of the full nutrient content  of foods.',\n",
       "   'The principle behind raw foodism is that plant foods in  their natural state are the most wholesome for the body.',\n",
       "   'The raw  food diet is not a weight-loss plan, it is a lifestyle choice.',\n",
       "   'People who  practice raw foodism eat only uncooked and unprocessed foods,  emphasizing whole fruits and vegetables.',\n",
       "   'Staples of the raw food  diet include whole grains, beans, dried fruits, seeds and nuts,  seaweed, sprouts, and unprocessed produce.',\n",
       "   'As a result, food  preparation mostly involves peeling, chopping, blending, straining,  and dehydrating fruits and vegetables.',\n",
       "   ' The positive aspects of this eating method include consuming  foods that are high in fiber and nutrients, and low in calories and  saturated fat.',\n",
       "   'However, the raw food diet offers little in the way of  protein, dairy, or fats, which can cause deficiencies of the vitamins  A, D, E, and K. In addition, not all foods are healthier uncooked,  such as spinach and tomatoes.',\n",
       "   'Also, cooking eliminates potentially  11.',\n",
       "   'More Olive Oil in Diet Could Cut Stroke Risk: Study.',\n",
       "   ' MedicineNet.com.',\n",
       "   'https://www.medicinenet.com/ script/main/art.asp?articlekey=145823.',\n",
       "   'Published 2011.',\n",
       "   ' Accessed April 15,2018.',\n",
       "   ' 1056  |  Comparing Diets'],\n",
       "  'page_sentence_count_spacy': 15}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect an example\n",
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd13228",
   "metadata": {},
   "source": [
    "Wonderful!\n",
    "\n",
    "Now let's turn out list of dictionaries into a DataFrame and get some stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa39116e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>199.50</td>\n",
       "      <td>10.52</td>\n",
       "      <td>287.00</td>\n",
       "      <td>10.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.83</td>\n",
       "      <td>6.55</td>\n",
       "      <td>140.10</td>\n",
       "      <td>6.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>190.50</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>216.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>272.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>400.88</td>\n",
       "      <td>15.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>430.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>577.00</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1208.00          1208.00          1208.00                  1208.00   \n",
       "mean        562.50          1148.00           199.50                    10.52   \n",
       "std         348.86           560.38            95.83                     6.55   \n",
       "min         -41.00             0.00             1.00                     1.00   \n",
       "25%         260.75           762.00           134.00                     5.00   \n",
       "50%         562.50          1231.50           216.00                    10.00   \n",
       "75%         864.25          1603.50           272.00                    15.00   \n",
       "max        1166.00          2308.00           430.00                    39.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  \n",
       "count           1208.00                    1208.00  \n",
       "mean             287.00                      10.32  \n",
       "std              140.10                       6.30  \n",
       "min                0.00                       0.00  \n",
       "25%              190.50                       5.00  \n",
       "50%              307.88                      10.00  \n",
       "75%              400.88                      15.00  \n",
       "max              577.00                      28.00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a40106",
   "metadata": {},
   "source": [
    "For our set of text, it looks like our raw sentence count (e.g. splitting on `\". \"`) is quite close to what spaCy came up with.\n",
    "\n",
    "Now we've got our text split into sentences, how about we group those sentences?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c61170",
   "metadata": {},
   "source": [
    "### Chunking our sentences together\n",
    "\n",
    "Let's take a step to break down our list of sentences/text into smaller chunks.\n",
    "\n",
    "As you might've guessed, this process is referred to as **chunking**.\n",
    "\n",
    "Why do we do this?\n",
    "\n",
    "1. Easier to manage similar sized chunks of text.\n",
    "2. Don't overload the embedding models capacity for tokens (e.g. if an embedding model has a capacity of 384 tokens, there could be information loss if you try to embed a sequence of 400+ tokens).\n",
    "3. Our LLM context window (the amount of tokens an LLM can take in) may be limited and requires compute power so we want to make sure we're using it as well as possible.\n",
    "\n",
    "Something to note is that there are many different ways emerging for creating chunks of information/text.\n",
    "\n",
    "For now, we're going to keep it simple and break our pages of sentences into groups of 10 (this number is arbitrary and can be changed, I just picked it because it seemed to line up well with our embedding model capacity of 384).\n",
    "\n",
    "On average each of our pages has 10 sentences.\n",
    "\n",
    "And an average total of 287 tokens per page.\n",
    "\n",
    "So our groups of 10 sentences will also be ~287 tokens long.\n",
    "\n",
    "This gives us plenty of room for the text to embedded by our `all-mpnet-base-v2` model (it has a capacity of 384 tokens).\n",
    "\n",
    "To split our groups of sentences into chunks of 10 or less, let's create a function which accepts a list as input and recursively breaks into down into sublists of a specified size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a342c720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3af217a54e47299f06de51814ec1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define split size to turn groups of sentences into chunks\n",
    "num_sentence_chunk_size = 10 \n",
    "\n",
    "# Create a function that recursively splits a list into desired sizes\n",
    "def split_list(input_list: list, \n",
    "               slice_size: int) -> list[list[str]]:\n",
    "    \"\"\"\n",
    "    Splits the input_list into sublists of size slice_size (or as close as possible).\n",
    "\n",
    "    For example, a list of 17 sentences would be split into two lists of [[10], [7]]\n",
    "    \"\"\"\n",
    "    return [input_list[i:i + slice_size] for i in range(0, len(input_list), slice_size)]\n",
    "\n",
    "# Loop through pages and texts and split sentences into chunks\n",
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                         slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72fb58b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 980,\n",
       "  'page_char_count': 1483,\n",
       "  'page_word_count': 248,\n",
       "  'page_sentence_count_raw': 12,\n",
       "  'page_token_count': 370.75,\n",
       "  'text': 'FDA has proven that they are hazardous.3 To revisit the topic of  structural and functional claims refer back to Chapter 12 “Nutrition  Applications”.  Before Taking Supplements  The phrase caveat emptor means “buyer beware,” and it is important  to keep the term in mind when considering supplementation. Just  because a product is “natural” does not mean it can’t be harmful  or dangerous, particularly if used inappropriately. The following are  helpful questions to explore before deciding to take a supplement:  • Does the scientific community understand how this  supplement works and are all its effects well known?  • Is there proof that the supplement actually performs in the  manner that it claims?  • Does this supplement interact with food or medication?  • Is taking this supplement necessary for my health?  • Is the supplement affordable?  • Is the supplement safe and free from contaminants?  Lastly, please remember that a supplement is only as good as the  diet that accompanies it. We cannot overstate the importance of  eating a healthy, well-balanced diet designed to provide all of the  necessary  nutrients.  Food  contains  many  more  beneficial  substances, such as phytochemicals and fiber, that promote good  3. Watson S. How to Evaluate Vitamins and Supplements.  WebMD.com. http://www.webmd.com/vitamins-and- supplements/lifestyle-guide -11/how-to-evaluate- vitamins-supplements. Accessed March 11, 2018.  980  |  Food Supplements and Food Replacements',\n",
       "  'sentences': ['FDA has proven that they are hazardous.3 To revisit the topic of  structural and functional claims refer back to Chapter 12 “Nutrition  Applications”.',\n",
       "   ' Before Taking Supplements  The phrase caveat emptor means “buyer beware,” and it is important  to keep the term in mind when considering supplementation.',\n",
       "   'Just  because a product is “natural” does not mean it can’t be harmful  or dangerous, particularly if used inappropriately.',\n",
       "   'The following are  helpful questions to explore before deciding to take a supplement:  • Does the scientific community understand how this  supplement works and are all its effects well known?',\n",
       "   ' • Is there proof that the supplement actually performs in the  manner that it claims?',\n",
       "   ' • Does this supplement interact with food or medication?',\n",
       "   ' • Is taking this supplement necessary for my health?',\n",
       "   ' • Is the supplement affordable?',\n",
       "   ' • Is the supplement safe and free from contaminants?',\n",
       "   ' Lastly, please remember that a supplement is only as good as the  diet that accompanies it.',\n",
       "   'We cannot overstate the importance of  eating a healthy, well-balanced diet designed to provide all of the  necessary  nutrients.',\n",
       "   ' Food  contains  many  more  beneficial  substances, such as phytochemicals and fiber, that promote good  3.',\n",
       "   'Watson S. How to Evaluate Vitamins and Supplements.',\n",
       "   ' WebMD.com.',\n",
       "   'http://www.webmd.com/vitamins-and- supplements/lifestyle-guide -11/how-to-evaluate- vitamins-supplements.',\n",
       "   'Accessed March 11, 2018.',\n",
       "   ' 980  |  Food Supplements and Food Replacements'],\n",
       "  'page_sentence_count_spacy': 17,\n",
       "  'sentence_chunks': [['FDA has proven that they are hazardous.3 To revisit the topic of  structural and functional claims refer back to Chapter 12 “Nutrition  Applications”.',\n",
       "    ' Before Taking Supplements  The phrase caveat emptor means “buyer beware,” and it is important  to keep the term in mind when considering supplementation.',\n",
       "    'Just  because a product is “natural” does not mean it can’t be harmful  or dangerous, particularly if used inappropriately.',\n",
       "    'The following are  helpful questions to explore before deciding to take a supplement:  • Does the scientific community understand how this  supplement works and are all its effects well known?',\n",
       "    ' • Is there proof that the supplement actually performs in the  manner that it claims?',\n",
       "    ' • Does this supplement interact with food or medication?',\n",
       "    ' • Is taking this supplement necessary for my health?',\n",
       "    ' • Is the supplement affordable?',\n",
       "    ' • Is the supplement safe and free from contaminants?',\n",
       "    ' Lastly, please remember that a supplement is only as good as the  diet that accompanies it.'],\n",
       "   ['We cannot overstate the importance of  eating a healthy, well-balanced diet designed to provide all of the  necessary  nutrients.',\n",
       "    ' Food  contains  many  more  beneficial  substances, such as phytochemicals and fiber, that promote good  3.',\n",
       "    'Watson S. How to Evaluate Vitamins and Supplements.',\n",
       "    ' WebMD.com.',\n",
       "    'http://www.webmd.com/vitamins-and- supplements/lifestyle-guide -11/how-to-evaluate- vitamins-supplements.',\n",
       "    'Accessed March 11, 2018.',\n",
       "    ' 980  |  Food Supplements and Food Replacements']],\n",
       "  'num_chunks': 2}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sample an example from the group (note: many samples have only 1 chunk as they have <=10 sentences total)\n",
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9037107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "      <td>1208.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1148.00</td>\n",
       "      <td>199.50</td>\n",
       "      <td>10.52</td>\n",
       "      <td>287.00</td>\n",
       "      <td>10.32</td>\n",
       "      <td>1.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>348.86</td>\n",
       "      <td>560.38</td>\n",
       "      <td>95.83</td>\n",
       "      <td>6.55</td>\n",
       "      <td>140.10</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>260.75</td>\n",
       "      <td>762.00</td>\n",
       "      <td>134.00</td>\n",
       "      <td>5.00</td>\n",
       "      <td>190.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>562.50</td>\n",
       "      <td>1231.50</td>\n",
       "      <td>216.00</td>\n",
       "      <td>10.00</td>\n",
       "      <td>307.88</td>\n",
       "      <td>10.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>864.25</td>\n",
       "      <td>1603.50</td>\n",
       "      <td>272.00</td>\n",
       "      <td>15.00</td>\n",
       "      <td>400.88</td>\n",
       "      <td>15.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>2308.00</td>\n",
       "      <td>430.00</td>\n",
       "      <td>39.00</td>\n",
       "      <td>577.00</td>\n",
       "      <td>28.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1208.00          1208.00          1208.00                  1208.00   \n",
       "mean        562.50          1148.00           199.50                    10.52   \n",
       "std         348.86           560.38            95.83                     6.55   \n",
       "min         -41.00             0.00             1.00                     1.00   \n",
       "25%         260.75           762.00           134.00                     5.00   \n",
       "50%         562.50          1231.50           216.00                    10.00   \n",
       "75%         864.25          1603.50           272.00                    15.00   \n",
       "max        1166.00          2308.00           430.00                    39.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
       "count           1208.00                    1208.00     1208.00  \n",
       "mean             287.00                      10.32        1.53  \n",
       "std              140.10                       6.30        0.64  \n",
       "min                0.00                       0.00        0.00  \n",
       "25%              190.50                       5.00        1.00  \n",
       "50%              307.88                      10.00        1.00  \n",
       "75%              400.88                      15.00        2.00  \n",
       "max              577.00                      28.00        3.00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to get stats\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a3d1a3",
   "metadata": {},
   "source": [
    "Note how the average number of chunks is around 1.5, this is expected since many of our pages only contain an average of 10 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daad5d9b",
   "metadata": {},
   "source": [
    "### Splitting each chunk into its own item\n",
    "\n",
    "We'd like to embed each chunk of sentences into its own numerical representation.\n",
    "\n",
    "So to keep things clean, let's create a new list of dictionaries each containing a single chunk of sentences with relative information such as page number as well statistics about each chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34f4afac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4a9b5285c224bdd8a9d2e3372dc7394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1843"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Split each chunk into its own item\n",
    "pages_and_chunks = []\n",
    "for item in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in item[\"sentence_chunks\"]:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = item[\"page_number\"]\n",
    "        \n",
    "        # Join the sentences together into a paragraph-like structure, aka a chunk (so they are a single string)\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk) # \".A\" -> \". A\" for any full-stop/capital letter combo \n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "\n",
    "        # Get stats about the chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4 # 1 token = ~4 characters\n",
    "        \n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "\n",
    "# How many chunks do we have?\n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6268970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 414,\n",
       "  'sentence_chunk': 'Foods that contain some of the essential amino acids are called incomplete protein sources, while those that contain all nine essential amino acids are called complete protein sources, or high- quality protein sources. Foods that are complete protein sources include animal foods such as milk, cheese, eggs, fish, poultry, and meat, and a few plant foods, such as soy and quinoa. The only animal-based protein that is not complete is gelatin, which is made of the protein, collagen. Figure 6.18 Complete and Incomplete Protein Sources 414 | Proteins, Diet, and Personal Choices',\n",
       "  'chunk_char_count': 577,\n",
       "  'chunk_word_count': 92,\n",
       "  'chunk_token_count': 144.25}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a56de4d",
   "metadata": {},
   "source": [
    "Excellent!\n",
    "\n",
    "Now we've broken our whole textbook into chunks of 10 sentences or less as well as the page number they came from.\n",
    "\n",
    "This means we could reference a chunk of text and know its source.\n",
    "\n",
    "Let's get some stats about our chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a97cd4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "      <td>1843.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>583.38</td>\n",
       "      <td>734.10</td>\n",
       "      <td>112.74</td>\n",
       "      <td>183.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>347.79</td>\n",
       "      <td>447.51</td>\n",
       "      <td>71.24</td>\n",
       "      <td>111.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-41.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>280.50</td>\n",
       "      <td>315.00</td>\n",
       "      <td>45.00</td>\n",
       "      <td>78.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>586.00</td>\n",
       "      <td>745.00</td>\n",
       "      <td>115.00</td>\n",
       "      <td>186.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>890.00</td>\n",
       "      <td>1118.00</td>\n",
       "      <td>173.00</td>\n",
       "      <td>279.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1166.00</td>\n",
       "      <td>1830.00</td>\n",
       "      <td>297.00</td>\n",
       "      <td>457.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count      1843.00           1843.00           1843.00            1843.00\n",
       "mean        583.38            734.10            112.74             183.52\n",
       "std         347.79            447.51             71.24             111.88\n",
       "min         -41.00             12.00              3.00               3.00\n",
       "25%         280.50            315.00             45.00              78.75\n",
       "50%         586.00            745.00            115.00             186.25\n",
       "75%         890.00           1118.00            173.00             279.50\n",
       "max        1166.00           1830.00            297.00             457.50"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame to get stats\n",
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a26a5b5",
   "metadata": {},
   "source": [
    "Hmm looks like some of our chunks have quite a low token count.\n",
    "\n",
    "How about we check for samples with less than 30 tokens (about the length of a sentence) and see if they are worth keeping?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1834fb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 23.0 | Text: view it online here: http://pressbooks.oer.hawaii.edu/ humannutrition2/?p=301 The Atom | 471\n",
      "Chunk token count: 28.75 | Text: Accessed September 22, 2017. Dietary, Behavioral, and Physical Activity Recommendations for Weight Management | 507\n",
      "Chunk token count: 19.25 | Text: The function of the anticoagulant drug warfarin is 544 | Fat-Soluble Vitamins\n",
      "Chunk token count: 16.5 | Text: Updated March 12, 2015. Accessed December 5, 2017. 882 | Childhood\n",
      "Chunk token count: 20.5 | Text: PART XVI CHAPTER 16. PERFORMANCE NUTRITION Chapter 16. Performance Nutrition | 931\n"
     ]
    }
   ],
   "source": [
    "# Show random chunks with under 30 tokens in length\n",
    "min_token_length = 30\n",
    "for row in df[df[\"chunk_token_count\"] <= min_token_length].sample(5).iterrows():\n",
    "    print(f'Chunk token count: {row[1][\"chunk_token_count\"]} | Text: {row[1][\"sentence_chunk\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b91233c",
   "metadata": {},
   "source": [
    "Looks like many of these are headers and footers of different pages.\n",
    "\n",
    "They don't seem to offer too much information.\n",
    "\n",
    "Let's filter our DataFrame/list of dictionaries to only include chunks with over 30 tokens in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fb21585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': -39,\n",
       "  'sentence_chunk': 'Human Nutrition: 2020 Edition UNIVERSITY OF HAWAI‘I AT MĀNOA FOOD SCIENCE AND HUMAN NUTRITION PROGRAM ALAN TITCHENAL, SKYLAR HARA, NOEMI ARCEO CAACBAY, WILLIAM MEINKE-LAU, YA-YUN YANG, MARIE KAINOA FIALKOWSKI REVILLA, JENNIFER DRAPER, GEMADY LANGFELDER, CHERYL GIBBY, CHYNA NICOLE CHUN, AND ALLISON CALABRESE',\n",
       "  'chunk_char_count': 308,\n",
       "  'chunk_word_count': 42,\n",
       "  'chunk_token_count': 77.0},\n",
       " {'page_number': -38,\n",
       "  'sentence_chunk': 'Human Nutrition: 2020 Edition by University of Hawai‘i at Mānoa Food Science and Human Nutrition Program is licensed under a Creative Commons Attribution 4.0 International License, except where otherwise noted.',\n",
       "  'chunk_char_count': 210,\n",
       "  'chunk_word_count': 30,\n",
       "  'chunk_token_count': 52.5}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_length].to_dict(orient=\"records\")\n",
    "pages_and_chunks_over_min_token_len[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a5efea",
   "metadata": {},
   "source": [
    "Smaller chunks filtered!\n",
    "\n",
    "Time to embed our chunks of text!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8b8241",
   "metadata": {},
   "source": [
    "### Embedding our text chunks\n",
    "\n",
    "While humans understand text, machines understand numbers best.\n",
    "\n",
    "An [embedding](https://vickiboykis.com/what_are_embeddings/index.html) is a broad concept.\n",
    "\n",
    "The most powerful thing about modern embeddings is that they are *learned* representations.\n",
    "\n",
    "Meaning rather than directly mapping words/tokens/characters to numbers directly (e.g. `{\"a\": 0, \"b\": 1, \"c\": 3...}`), the numerical representation of tokens is learned by going through large corpuses of text and figuring out how different tokens relate to each other.\n",
    "\n",
    "Ideally, embeddings of text will mean that similar meaning texts have similar numerical representation.\n",
    "\n",
    "\n",
    "Our goal is to turn each of our chunks into a numerical representation (an embedding vector, where a vector is a sequence of numbers arranged in order).\n",
    "\n",
    "Once our text samples are in embedding vectors, us humans will no longer be able to understand them.\n",
    "\n",
    "However, we don't need to.\n",
    "\n",
    "The embedding vectors are for our computers to understand.\n",
    "\n",
    "We'll use our computers to find patterns in the embeddings and then we can use their text mappings to further our understanding.\n",
    "\n",
    "Enough talking, how about we import a text embedding model and see what an embedding looks like.\n",
    "\n",
    "To do so, we'll use the [`sentence-transformers`](https://www.sbert.net/docs/installation.html) library which contains many pre-trained embedding models.\n",
    "\n",
    "Specifically, we'll get the `all-mpnet-base-v2` model (you can see the model's intended use on the [Hugging Face model card](https://huggingface.co/sentence-transformers/all-mpnet-base-v2#intended-uses))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53de432d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I like football\n",
      "Embeddings: [-8.42475444e-02  1.00637212e-01 -3.04262508e-02 -4.04835865e-03\n",
      "  3.78771499e-02  3.74091119e-02 -9.98117849e-02  2.61343946e-03\n",
      "  1.68801006e-02 -1.06646698e-02 -9.36578587e-03 -4.31236029e-02\n",
      "  7.33321533e-03  1.65348276e-02  1.87982209e-02 -7.59599684e-03\n",
      " -2.98678111e-02 -2.66341437e-02  1.27094649e-02 -1.01594571e-02\n",
      "  8.85396637e-03  4.13204506e-02 -1.35907661e-02 -4.72090393e-02\n",
      " -1.78263839e-02  4.68517244e-02 -7.70462630e-03 -4.88640293e-02\n",
      " -3.99428159e-02  1.04912810e-01 -1.95646044e-02 -3.23913395e-02\n",
      " -5.61739877e-02 -5.53603768e-02  1.33881906e-06  1.68700833e-02\n",
      " -7.19039282e-03 -2.36500334e-02  6.86780587e-02  2.94983350e-02\n",
      "  4.66499925e-02  3.60918837e-03 -4.46939059e-02 -4.21173312e-02\n",
      " -1.59445629e-02  4.67798449e-02  3.78085896e-02  2.07526819e-03\n",
      " -2.71698646e-02  1.42831588e-02  5.78409992e-03 -4.98900842e-03\n",
      " -5.02601489e-02 -1.26381991e-02 -4.07727212e-02  1.14967311e-02\n",
      "  3.48693170e-02  2.09056195e-02  3.40205804e-02  4.15206663e-02\n",
      "  2.47722268e-02 -5.56736030e-02 -5.39382966e-03 -5.16379438e-03\n",
      " -4.75414358e-02  2.79134046e-02  7.07969442e-02 -1.93239446e-03\n",
      "  2.12249365e-02 -1.97552319e-04 -8.77789482e-02 -2.01519076e-02\n",
      " -4.30815248e-03  2.50273179e-02  1.37650277e-02 -5.19346260e-02\n",
      " -4.57388647e-02  5.02928644e-02  2.15829518e-02 -1.40141137e-02\n",
      "  4.01836149e-02  4.16770242e-02  6.32853014e-03  1.10610295e-02\n",
      " -3.42051201e-02  1.14572924e-02  2.74630766e-02  1.97202452e-02\n",
      "  1.11586526e-02  3.97156887e-02 -5.20722568e-02 -2.33238339e-02\n",
      "  2.82056183e-02  2.76915096e-02 -5.59915639e-02 -1.88611858e-02\n",
      " -3.26372758e-02  7.00356788e-04  1.49081303e-02 -4.69959565e-02\n",
      "  2.92534046e-02  5.01979254e-02  1.44609446e-02  1.07252412e-02\n",
      "  1.71034727e-02 -1.61904804e-02  1.94008071e-02 -3.67493033e-02\n",
      "  1.97742358e-02  3.02425101e-02 -2.32428480e-02 -3.38912457e-02\n",
      "  6.20148964e-02  7.67265409e-02 -6.87961280e-02  4.04021554e-02\n",
      "  1.47981467e-02  6.06796183e-02  1.84311457e-02  1.51239634e-02\n",
      "  2.10779812e-02 -2.61135586e-02  4.23340872e-02  5.12265973e-02\n",
      " -9.42042843e-03  6.99340506e-03 -7.13938698e-02  2.93005817e-02\n",
      " -2.08076686e-02 -3.55476327e-02 -5.80607206e-02 -3.05647217e-02\n",
      " -5.98830823e-03 -4.97027300e-03  5.04765771e-02 -6.29104972e-02\n",
      " -5.75689264e-02  6.68658316e-03 -2.14008475e-03 -1.81987360e-02\n",
      "  6.99582696e-03 -4.92517576e-02  1.43193789e-02 -2.51797074e-03\n",
      " -1.84805132e-02 -9.19775851e-03  3.74320429e-03 -1.29442718e-02\n",
      "  7.34594185e-03  3.90475616e-02  2.28566565e-02  1.10025723e-02\n",
      " -7.77295157e-02  6.71035564e-03  7.38958921e-03  1.09679969e-02\n",
      "  2.75377426e-02 -2.36063674e-02 -9.62760393e-03  1.65471248e-02\n",
      "  1.92160252e-02  3.00923996e-02 -1.09887589e-02  9.89481807e-04\n",
      " -3.55859734e-02 -6.70885220e-02  2.64994670e-02 -4.45276592e-03\n",
      " -2.56287884e-02 -2.01323945e-02 -1.35247540e-02 -7.76847359e-03\n",
      " -2.25988906e-02 -7.59532303e-02  7.82441944e-02  2.68173907e-02\n",
      "  8.24524462e-02 -3.75438146e-02 -2.34529320e-02 -3.12519372e-02\n",
      " -2.98749506e-02 -4.14341278e-02  5.76486252e-02  2.70741023e-02\n",
      " -2.69436231e-03  9.41387936e-03 -2.34416407e-02  8.54085684e-02\n",
      " -3.62553522e-02 -3.21777686e-02  4.57366817e-02 -1.55808125e-02\n",
      "  3.60688046e-02  1.48086147e-02  4.02978063e-03 -6.21285071e-05\n",
      "  1.62415057e-02 -2.41479315e-02  4.22139280e-02 -2.18119193e-03\n",
      " -1.14807263e-02 -1.54284341e-02  4.50379662e-02 -3.55473608e-02\n",
      "  1.90483294e-02 -6.55420572e-02 -6.85998350e-02 -5.79103967e-03\n",
      "  7.56263062e-02  1.33733107e-02  1.37130702e-02  1.52509874e-02\n",
      "  8.20295066e-02 -1.66048035e-02  2.32107565e-02  6.87709963e-03\n",
      "  1.20373359e-02 -3.14195789e-02  7.21315201e-03  3.55870277e-02\n",
      " -4.53375354e-02 -2.88249105e-02  8.19241442e-03  4.70319912e-02\n",
      " -2.83143278e-02 -1.70615446e-02  6.85482100e-02  2.70877257e-02\n",
      " -1.42026935e-02  1.92857292e-02  1.08334469e-02 -1.58385579e-02\n",
      "  1.85037423e-02  2.82974943e-04  5.83866686e-02 -1.97079107e-02\n",
      "  7.21546412e-02 -4.88322275e-03 -2.70334110e-02 -3.83967012e-02\n",
      "  7.76601536e-03  6.82347044e-02  2.78944224e-02  3.94895263e-02\n",
      "  1.63869504e-02 -9.74451378e-03  7.86119327e-02  3.70756770e-03\n",
      " -4.52783890e-02 -2.87718214e-02 -1.70555208e-02 -1.13031296e-02\n",
      "  6.51996117e-03  3.34491134e-02 -3.05923820e-02 -8.59767199e-02\n",
      " -5.59616908e-02  1.63754653e-02 -3.53234150e-02 -4.35333177e-02\n",
      "  1.18040092e-01 -3.00700609e-02 -2.91675869e-02  5.31348027e-02\n",
      "  8.05326272e-03 -4.70534042e-02  3.42307612e-03 -5.87369315e-02\n",
      "  7.74148153e-03 -2.87119988e-02 -1.03800287e-02 -3.28244902e-02\n",
      "  2.19958387e-02  1.60498004e-02  7.74394069e-03  2.10018698e-02\n",
      " -7.76350126e-02 -1.83953904e-02  3.70450015e-03  6.00363826e-03\n",
      "  9.62629262e-03  6.25347644e-02  1.62003674e-02  1.65151618e-02\n",
      "  1.36423847e-02 -2.73847999e-03 -5.40273497e-03 -2.26999763e-02\n",
      "  1.63578894e-02  1.99065395e-02  8.42060763e-05 -5.21967001e-03\n",
      "  8.64645559e-03  7.25503732e-03 -2.93584876e-02 -1.93263609e-02\n",
      " -2.67649256e-02 -2.36762147e-02 -1.57548226e-02 -6.06270619e-02\n",
      " -4.61213756e-03 -5.11957109e-02  2.52245907e-02  3.51109579e-02\n",
      " -1.74153540e-02 -4.54435088e-02 -3.07275299e-02 -4.58775321e-03\n",
      "  9.63255577e-03  4.35629524e-02 -2.95853261e-02 -2.98219491e-02\n",
      " -3.17400619e-02 -1.42361764e-02  4.54285927e-02  6.19675294e-02\n",
      " -2.35949587e-02  1.12946669e-04  4.58987281e-02 -1.00664580e-02\n",
      " -1.11280624e-02  5.16887195e-02  3.36655825e-02  3.80756147e-02\n",
      " -3.92877422e-02  1.62376673e-03 -5.14691696e-02  2.75075883e-02\n",
      "  4.87785004e-02 -5.81608899e-03  2.09721867e-02  3.64104025e-02\n",
      "  3.88538316e-02  3.02592758e-02  6.01187861e-03 -2.41591055e-02\n",
      "  2.66468595e-03  7.41400803e-03  5.48147364e-03 -2.19564904e-02\n",
      "  3.40091772e-02  9.45102982e-03 -3.10383886e-02 -7.56968707e-02\n",
      " -1.85929723e-02 -5.34317875e-03 -1.37087591e-02  3.24455947e-02\n",
      " -1.01340413e-01 -3.77967767e-02  5.66013567e-02 -8.38874727e-02\n",
      " -5.25772525e-03 -1.95408035e-02  2.80081723e-02  5.89934774e-02\n",
      "  2.29245927e-02  1.66056324e-02 -6.21854477e-02 -2.64082197e-02\n",
      " -1.08168565e-03  7.62561634e-02  2.62288488e-02  3.84933874e-02\n",
      " -1.47654666e-02  6.05497416e-03  6.29490316e-02 -2.53709145e-02\n",
      " -4.00721319e-02  2.32962370e-02 -6.68872893e-03  4.88928426e-03\n",
      " -4.29552346e-02  1.11140488e-02  9.09431931e-03  6.94774836e-02\n",
      "  1.64371822e-02  2.46265903e-02  3.53869423e-02 -3.55380140e-02\n",
      "  5.38688377e-02 -3.27346958e-02 -2.74584256e-02  2.26424094e-02\n",
      " -1.24993389e-02 -6.74723648e-03  2.70586535e-02 -2.07670201e-02\n",
      " -2.06278004e-02 -2.85870507e-02  4.28662784e-02  4.11972357e-03\n",
      " -1.10182919e-01 -6.22343831e-02  2.10633576e-02  1.69574760e-03\n",
      " -3.27287726e-02  4.77167368e-02  1.11153778e-02  2.17695013e-02\n",
      " -2.52284436e-03  5.02349585e-02 -5.10567008e-03  3.80875282e-02\n",
      " -1.71695054e-02  3.43375392e-02 -2.13631894e-02  1.73857808e-02\n",
      "  2.54417323e-02 -5.33008687e-02 -2.64375508e-02  2.22395211e-02\n",
      "  9.24143288e-03 -5.06643904e-04 -2.25211028e-03 -2.99091935e-02\n",
      "  1.48480721e-02  1.35684395e-02  6.24463521e-02 -4.34339345e-02\n",
      " -4.65225428e-02  3.55718378e-03  9.30303484e-02 -1.63256802e-04\n",
      " -1.74396727e-02  1.16810566e-02  2.71258615e-02  3.93609926e-02\n",
      " -3.20859961e-02 -3.65100205e-02  2.23816447e-02 -3.07413377e-02\n",
      " -2.08535697e-02  5.93941882e-02 -1.34406704e-02 -8.53671879e-02\n",
      " -2.68324241e-02  6.50370643e-02 -5.58489710e-02  2.90103573e-02\n",
      " -2.32818816e-02  1.80063280e-03  1.86815858e-03 -5.57178669e-02\n",
      "  3.62724550e-02 -1.13221072e-02 -4.15317565e-02 -4.26012687e-02\n",
      " -3.14608887e-02  5.70976920e-02  1.88349315e-03  3.27453464e-02\n",
      " -2.14030165e-02  7.43865222e-02  1.53319761e-02 -2.07311586e-02\n",
      "  1.98257584e-02 -1.84399970e-02  4.12098393e-02  3.26042734e-02\n",
      "  7.27778897e-02  7.42723513e-03  9.58934601e-04  2.86802519e-02\n",
      "  2.15338040e-02 -4.33621183e-02 -1.46020185e-02  8.65049008e-03\n",
      "  1.58613957e-02 -1.55544132e-02 -4.37542610e-02 -1.35810710e-02\n",
      " -2.85271667e-02 -3.34967277e-03  4.43325415e-02  7.98118785e-02\n",
      "  7.44022243e-03 -6.09604828e-02 -4.35516750e-03 -5.11232764e-02\n",
      " -7.27273407e-04  5.59347384e-02 -1.33643262e-02  2.02866886e-02\n",
      "  2.60682851e-02 -6.01524208e-03 -3.60819884e-03 -1.76506452e-02\n",
      "  2.79661622e-02 -4.57974933e-02  4.21607159e-02 -2.65814550e-02\n",
      " -1.72598585e-02 -3.59776467e-02 -2.97338795e-02  5.95300533e-02\n",
      "  1.74915176e-02 -2.48561557e-02  5.11112018e-03 -6.37427531e-03\n",
      " -8.68559033e-02  3.45525425e-03  1.45450784e-02  5.42752743e-02\n",
      "  7.10134879e-02 -3.47637646e-02  2.00921372e-02 -1.34610413e-02\n",
      " -3.85139845e-02  2.38078786e-03  2.00647824e-02 -2.93172058e-02\n",
      "  4.07206528e-02  1.70541722e-02  2.59609725e-02 -4.38436749e-04\n",
      "  2.57690102e-02 -6.63422868e-02 -5.44347614e-02 -3.35697941e-02\n",
      "  3.87411052e-03  2.16774680e-02  4.67668613e-03  3.12814564e-02\n",
      " -1.34410383e-02  4.32044789e-02  8.03099573e-03 -4.20283489e-02\n",
      "  6.53893827e-03 -2.43937876e-03 -6.02266705e-03 -3.47500034e-02\n",
      "  3.65685150e-02 -5.30309379e-02 -5.38329668e-02  7.03010336e-03\n",
      "  4.12302651e-02  8.45791921e-02 -5.03538549e-02  7.66277164e-02\n",
      " -2.78607514e-02  7.90916905e-02  3.97939198e-02 -4.55360152e-02\n",
      "  3.14156413e-02 -2.69393646e-03  5.28775081e-02  2.48770341e-02\n",
      "  4.99717146e-03  1.64268222e-02 -1.69216115e-02  2.48392168e-02\n",
      " -1.22535098e-02 -3.69962007e-02 -6.34204447e-02 -6.39738409e-33\n",
      "  6.64366176e-03  1.38151860e-02 -2.38952041e-02 -4.83649084e-03\n",
      " -4.55578007e-02 -5.83923794e-02  3.37188281e-02  1.17862355e-02\n",
      "  1.92115437e-02  1.29556293e-02 -3.08516640e-02 -1.15106320e-02\n",
      " -3.26733425e-06  5.76784555e-03  4.48282734e-02 -6.07790463e-02\n",
      " -9.49648488e-03 -7.60856504e-03  1.54688144e-02 -1.52527320e-03\n",
      " -1.90541204e-02 -7.09424901e-04  1.32276537e-02  1.74561199e-02\n",
      "  1.25597557e-02  5.03845662e-02  2.25027502e-02 -3.98198329e-02\n",
      "  2.12818366e-02  3.72618735e-02  1.24223507e-03 -1.56132123e-02\n",
      " -9.33839288e-03 -3.27454396e-02  6.25485647e-03  1.05579302e-01\n",
      " -9.70495399e-04 -4.00631800e-02 -1.75544936e-02  8.08217749e-03\n",
      "  3.00003793e-02 -3.68314274e-02  6.16536699e-02 -5.05825318e-02\n",
      " -3.28604430e-02 -5.53884991e-02  4.49809805e-02  1.67714935e-02\n",
      "  3.44181322e-02 -6.66545480e-02 -3.80341224e-02  2.98349350e-03\n",
      " -1.30312219e-02 -5.92840230e-03 -2.02847106e-04 -4.41355035e-02\n",
      "  3.82058099e-02  4.26402129e-02 -4.14671237e-03  1.25948098e-02\n",
      " -4.92177121e-02  2.28946446e-03 -3.53488661e-02 -1.31224161e-02\n",
      "  8.84506572e-03  2.31276583e-02  1.33539438e-02  4.80641099e-03\n",
      " -1.04382578e-02 -5.61291501e-02 -1.79180149e-02 -1.29853068e-02\n",
      "  8.10094364e-03 -2.99938638e-02 -3.34588066e-03  1.79704893e-02\n",
      " -6.27134964e-02 -5.14751077e-02  1.47673720e-02  4.13221419e-02\n",
      "  5.43307001e-03  1.83464121e-02 -2.86416654e-02  2.01381017e-02\n",
      "  3.06110419e-02  1.15998611e-02  1.17117418e-02 -5.30699920e-03\n",
      " -7.85787776e-02 -2.07856763e-02  1.49661861e-02 -5.28002940e-02\n",
      "  2.94363149e-03  2.98029892e-02 -9.11381794e-04  2.87766976e-04\n",
      " -2.35569701e-02 -1.39983194e-02 -1.47770243e-02  3.07937618e-02\n",
      "  5.67799201e-03  3.50137390e-02  5.42525901e-03 -3.60845141e-02\n",
      " -1.26140481e-02  1.03833005e-02 -3.88637669e-02  5.20079918e-02\n",
      " -2.38925163e-02 -2.68223230e-02  1.18294256e-02  3.52228247e-02\n",
      "  4.69845198e-02 -1.61579892e-03  2.04463992e-02  1.69065166e-02\n",
      " -7.57211354e-03  5.69040608e-03 -6.36684075e-02 -1.35807022e-02\n",
      "  6.38104230e-02  1.31863980e-02 -6.03351183e-02 -2.71138293e-03\n",
      "  2.25720331e-02 -3.93813439e-02 -3.64355296e-02  1.11656170e-02\n",
      " -9.08709243e-02  9.08006541e-03  1.39201712e-02 -2.59274221e-03\n",
      "  2.05434873e-07 -3.06701921e-02 -4.07751941e-04 -3.55365500e-02\n",
      "  3.81792523e-02 -2.87687639e-03  3.37544382e-02 -1.56595930e-02\n",
      "  6.45715967e-02  4.45960136e-03  8.05239305e-02 -3.16427759e-04\n",
      "  1.35497109e-03  5.99789843e-02  1.86059736e-02 -2.26561795e-03\n",
      " -6.04191199e-02  1.95420291e-02 -2.39958465e-02  1.83382966e-02\n",
      " -7.44236857e-02 -4.47304547e-02  4.86414321e-02  7.85381421e-02\n",
      "  5.60332835e-02 -1.60649810e-02  7.88276568e-02 -8.80419801e-04\n",
      " -8.79179463e-02  3.92033393e-03  1.87990703e-02  3.33910733e-02\n",
      " -9.93275177e-03 -4.11850289e-02 -2.51307264e-02 -5.34668155e-02\n",
      " -2.37743445e-02  2.73193587e-02  6.14445563e-03  1.16724148e-02\n",
      "  6.07858561e-02 -5.32350466e-02  1.30301118e-02 -3.11416555e-02\n",
      "  2.86225844e-02 -1.36504229e-02 -4.83773649e-02 -3.76974866e-02\n",
      "  2.96162674e-03 -6.93949237e-02  6.10292796e-03 -3.55679281e-02\n",
      "  1.12396795e-02 -3.84193212e-02 -3.19854654e-02  1.63941439e-02\n",
      "  1.11979037e-03  5.47177047e-02 -4.52604936e-03  3.19908746e-02\n",
      "  6.30161688e-02 -4.07110080e-02  5.63861020e-02  1.62612610e-02\n",
      "  3.57900746e-02  1.39383618e-02 -7.90975895e-03 -4.02934030e-02\n",
      "  8.85369201e-35  3.63460183e-02 -1.91291142e-02 -2.66956501e-02\n",
      "  4.00693296e-03  1.32429937e-03 -4.12939563e-02  4.45932858e-02\n",
      "  1.36174662e-02  8.88671875e-02 -2.11695414e-02 -2.07189694e-02]\n",
      "\n",
      "Sentence: I like basketball\n",
      "Embeddings: [-6.22272491e-02  4.80107591e-02 -1.92648813e-03  5.26621146e-03\n",
      "  3.23529094e-02  5.39589636e-02 -8.73231664e-02  1.51895452e-02\n",
      "  2.51223613e-02 -3.56969275e-02 -2.87536979e-02 -8.97584856e-03\n",
      "  2.68125534e-02 -7.00396206e-03  7.83177465e-03  5.70327369e-03\n",
      " -3.62499803e-02  1.01661244e-02  5.49255908e-02 -9.18151345e-03\n",
      " -8.18465743e-03  4.99124825e-02 -7.11822836e-03 -4.66862880e-03\n",
      "  3.36747132e-02 -1.31412707e-02  8.41982290e-03 -6.85987771e-02\n",
      " -1.78071354e-02  7.39389434e-02 -5.23901395e-02 -1.97608694e-02\n",
      " -3.52292508e-02 -7.30900764e-02  1.21738890e-06  7.61763193e-03\n",
      "  3.61950397e-02  6.99661206e-03  5.57773560e-02  9.73270927e-03\n",
      "  1.22919111e-04 -1.69265196e-02 -2.02891696e-02 -2.33368464e-02\n",
      " -2.35559735e-02  2.06807181e-02  5.86124398e-02 -2.03836169e-02\n",
      " -3.31249721e-02  3.63546493e-03  2.10842974e-02 -7.75726419e-03\n",
      " -1.25995716e-02 -1.40486490e-02 -2.14152876e-03  2.19501033e-02\n",
      "  8.51616040e-02  2.52602808e-02  5.93740344e-02  2.50930972e-02\n",
      " -5.17571298e-03 -9.87883881e-02 -5.06000072e-02  8.34873319e-03\n",
      "  3.93843185e-03  1.78955551e-02  4.64148857e-02 -5.88242570e-03\n",
      "  3.01868040e-02  7.60082202e-03 -5.01487218e-02 -6.40114490e-03\n",
      "  6.87575154e-03  2.76278295e-02  4.48354967e-02 -2.52016708e-02\n",
      " -6.77500386e-03 -1.60643682e-02  1.68799926e-02 -1.92416087e-02\n",
      "  8.38974398e-03  2.13928111e-02  1.95603501e-02 -7.58345239e-03\n",
      " -2.46595051e-02  1.36145363e-02  2.34820023e-02  1.91808529e-02\n",
      " -3.29352356e-02  5.85882328e-02  1.93208735e-02 -4.41486388e-02\n",
      "  1.96587238e-02  1.74410306e-02 -6.19699284e-02 -1.63614806e-02\n",
      " -3.05542280e-03  2.44475547e-02  1.20044909e-02 -2.92989947e-02\n",
      "  6.69585392e-02  5.73725663e-02  1.17297219e-02  1.33876745e-02\n",
      " -1.81509964e-02  6.35559438e-03  5.93428984e-02 -1.46127222e-02\n",
      " -1.23241162e-02  1.85175613e-02 -4.13895696e-02  2.30874750e-03\n",
      "  2.92062946e-02  5.49965762e-02 -4.41697687e-02  5.01870066e-02\n",
      "  7.52534205e-03  6.09690100e-02  1.21231005e-02  1.10416878e-02\n",
      " -2.66692811e-03 -3.27570140e-02  4.06444818e-02  1.93506461e-02\n",
      "  3.44337360e-03 -3.87356780e-03 -8.97875130e-02  1.59464478e-02\n",
      " -2.08916198e-02 -8.33414197e-02 -3.93878892e-02 -3.25133689e-02\n",
      "  1.18559077e-02 -2.30156276e-02  5.75271212e-02  2.06397548e-02\n",
      " -1.45557756e-02 -2.26486493e-02  2.05442384e-02 -1.94978006e-02\n",
      " -2.83785611e-02 -4.55863215e-02  1.95394922e-02 -2.94630118e-02\n",
      "  1.09752445e-02  5.29949227e-03 -9.80913918e-03 -5.53408684e-03\n",
      " -1.02213211e-02  2.33999509e-02 -4.02921848e-02  2.75291633e-02\n",
      " -4.53095064e-02 -1.95818041e-02 -1.57546345e-02 -1.67317782e-02\n",
      "  6.13340214e-02 -6.12059087e-02 -2.18579601e-02 -2.83095744e-02\n",
      "  6.57709874e-03  1.07351588e-02  3.09909638e-02 -1.67897847e-02\n",
      " -3.68133634e-02 -3.94485630e-02  4.17384505e-03  8.16651061e-03\n",
      " -2.43421793e-02 -8.17458890e-03 -6.37402060e-03 -4.87153716e-02\n",
      " -4.65784371e-02 -2.54185759e-02  6.84609562e-02  5.83732910e-02\n",
      " -1.69725772e-02 -2.73225140e-02 -1.19513441e-02 -3.68439108e-02\n",
      " -2.30530296e-02 -7.62688667e-02  8.09230283e-02  1.69105586e-02\n",
      "  3.43637471e-03  4.54416461e-02 -2.09342502e-02  6.06311150e-02\n",
      " -3.80077064e-02 -6.10282719e-02  3.46028432e-02 -1.51100568e-02\n",
      " -1.48591613e-02  1.23012243e-02  9.37595591e-03 -1.61875598e-02\n",
      "  2.61782445e-02  4.97116037e-02  4.25596163e-02  4.57473751e-03\n",
      " -8.06291308e-03  1.73171461e-02  2.01369021e-02 -3.39020304e-02\n",
      " -3.17735597e-02 -4.36105616e-02 -2.58636810e-02 -2.25477549e-03\n",
      "  5.99334426e-02 -1.12337815e-02  1.39307510e-02  3.13673355e-02\n",
      "  6.50872365e-02 -4.30587120e-02  3.68172452e-02 -1.43092657e-02\n",
      "  5.39796203e-02 -4.06583361e-02 -1.15284640e-02  2.45578904e-02\n",
      " -5.63447177e-02  2.39986256e-02  9.21114087e-02  3.17167640e-02\n",
      " -4.25084643e-02  2.08772682e-02  1.04092635e-01  6.45273074e-04\n",
      "  4.49362211e-03  1.23556023e-02  2.80290116e-02 -6.26675552e-03\n",
      " -3.41615118e-02  2.67868731e-02  2.72684656e-02  2.37094983e-02\n",
      "  5.77911511e-02 -5.08044660e-02 -3.28829736e-02 -1.33932161e-03\n",
      "  1.80153400e-02  6.54260442e-03  4.41364758e-02  3.87614407e-02\n",
      "  4.09928448e-02  1.11093083e-02  8.30428749e-02  1.32515226e-02\n",
      " -3.22272740e-02 -1.03748674e-02 -4.78492230e-02 -2.58052461e-02\n",
      "  3.06266490e-02  4.38783653e-02 -5.21335343e-04 -1.82461850e-02\n",
      "  6.41377643e-04  8.14758521e-03  2.18761582e-02 -5.02126776e-02\n",
      "  1.03572920e-01 -5.25411814e-02 -5.48026189e-02  4.31574583e-02\n",
      " -1.94098614e-02 -1.11775135e-03  4.48058508e-02 -9.72971506e-03\n",
      "  2.79043745e-02 -6.02692738e-03 -3.71642299e-02 -5.12182154e-02\n",
      "  6.65680645e-03  2.37309616e-02  6.85667433e-03  1.01490095e-02\n",
      " -1.43088130e-02  8.79475567e-03 -1.06945122e-02  1.40770124e-02\n",
      " -9.61114932e-03  4.29820530e-02 -8.14293884e-03  6.96218153e-03\n",
      "  2.43589617e-02 -7.83307757e-03 -1.76933557e-02 -6.24113576e-03\n",
      " -4.98083094e-03  4.62234206e-02 -6.02036342e-03 -3.83356884e-02\n",
      " -6.78839674e-03  6.51707873e-03 -6.68900320e-03 -3.43001187e-02\n",
      " -4.89469543e-02 -2.00599972e-02  4.07541217e-03 -6.32264018e-02\n",
      "  3.66248041e-02 -6.03811070e-02  7.25981519e-02  2.48777643e-02\n",
      "  1.63273816e-03 -4.14175242e-02 -4.26661633e-02  2.29716636e-02\n",
      "  6.19905302e-03  3.72708552e-02  4.64051450e-03 -3.86467464e-02\n",
      " -4.04161401e-02 -5.06673120e-02  5.01261093e-02  6.54773116e-02\n",
      "  6.42693136e-03 -2.26248223e-02  8.12507048e-03 -3.47618386e-02\n",
      " -4.99704182e-02  4.35636863e-02  8.05452373e-03  3.59530151e-02\n",
      " -4.19094972e-02  2.12677568e-03 -4.48889919e-02  3.61827086e-03\n",
      "  2.67603137e-02 -2.97530030e-04  1.75167900e-02 -1.40003059e-02\n",
      "  3.72778401e-02  3.30388211e-02  2.47552153e-02 -3.95622440e-02\n",
      "  2.53535286e-02  7.29821669e-03  8.92106153e-04 -2.82260850e-02\n",
      "  6.83249533e-02 -1.42585803e-02 -1.57718807e-02  5.28142694e-03\n",
      " -6.27221093e-02 -2.33333334e-02 -2.28384323e-02 -1.42709725e-02\n",
      " -9.02765989e-02 -8.73969495e-02  4.69247922e-02 -9.23447236e-02\n",
      "  2.17867531e-02 -3.68620008e-02  5.16158622e-03  4.51893359e-02\n",
      "  1.00311218e-02  7.26890052e-03 -7.89989084e-02 -1.37210055e-03\n",
      " -1.70900545e-03  5.36523759e-02 -3.53705212e-02  3.94686908e-02\n",
      "  2.41867956e-02  3.38796936e-02  6.61817193e-02 -5.27016399e-03\n",
      " -7.55617395e-02  5.97741045e-02  1.66395665e-04 -1.04198488e-03\n",
      " -5.59063107e-02  2.27977764e-02  9.59182624e-03  1.88448112e-02\n",
      "  4.06849608e-02  3.71507257e-02 -1.25253201e-02 -5.28873876e-02\n",
      "  3.23249772e-02 -4.81804088e-02 -3.59884091e-02  2.72231102e-02\n",
      " -3.74460556e-02 -4.26430330e-02 -8.91751982e-03 -4.94932197e-02\n",
      " -8.20840672e-02 -2.19074544e-02  4.60920706e-02  9.68975574e-03\n",
      " -6.64374828e-02 -4.73582745e-02  6.15322143e-02 -3.13153490e-02\n",
      " -9.63102281e-03  4.44769626e-03  2.47762669e-02  2.37569716e-02\n",
      " -1.19248768e-02  4.13005576e-02  5.93949622e-03  2.17993371e-02\n",
      " -2.55940817e-02 -7.14307232e-03  7.10192020e-04  2.11563129e-02\n",
      "  5.87623974e-04  1.29017094e-02 -5.34296110e-02 -1.08021847e-03\n",
      " -2.90097063e-03 -8.58804770e-03  4.89120418e-03 -1.04394108e-02\n",
      "  2.42561232e-02 -1.23261604e-02  7.60536492e-02 -3.24492678e-02\n",
      " -3.75105962e-02 -3.12218517e-02  5.68580404e-02  4.34360728e-02\n",
      " -2.96102967e-02  4.36863899e-02 -9.16757528e-03 -1.29666189e-02\n",
      " -2.72127446e-02 -5.56946099e-02  4.00549807e-02 -4.41518845e-03\n",
      " -3.05867121e-02  6.90794662e-02 -7.53296092e-02 -8.56188014e-02\n",
      " -4.88807261e-02  8.67507160e-02 -1.86916739e-02 -8.47973488e-03\n",
      " -4.14148308e-02  1.25162853e-02  2.73346305e-02 -5.32191917e-02\n",
      "  3.03267166e-02 -2.06976067e-02 -4.25292887e-02 -5.93749546e-02\n",
      " -6.63804188e-02  2.72896737e-02  6.10590633e-03  3.50520052e-02\n",
      "  8.19267333e-03  3.24757509e-02  4.93208412e-04 -1.55680897e-02\n",
      "  3.05343214e-02 -8.06736294e-03  6.51803426e-03  2.09508222e-02\n",
      "  6.14110194e-02  6.02944056e-03  1.71777122e-02  3.52091305e-02\n",
      "  3.82577702e-02 -7.22996658e-03 -2.07848218e-03  1.29131088e-02\n",
      "  4.08537798e-02 -4.66254316e-02 -3.99282239e-02 -7.12412829e-03\n",
      " -3.13827284e-02 -2.16344092e-03  2.99163163e-02  7.27892816e-02\n",
      "  2.33910456e-02 -5.00748903e-02 -3.86200100e-02 -5.37739322e-02\n",
      " -3.04967016e-02  4.18373570e-02  1.84124224e-02 -2.45365384e-03\n",
      "  6.03914307e-03 -2.18064375e-02  5.02362964e-04  1.20579433e-02\n",
      " -1.53616099e-02 -7.65968114e-02  1.73336975e-02 -4.66602519e-02\n",
      " -4.52180915e-02  1.01748090e-02  8.94448254e-03  4.97487262e-02\n",
      "  1.32857971e-02 -3.64009105e-02 -1.74232963e-02  4.98526096e-02\n",
      " -5.34444824e-02  1.85468160e-02 -6.66272221e-03  3.13199274e-02\n",
      "  5.71382940e-02 -5.18840067e-02  2.89794207e-02  2.29748711e-03\n",
      " -2.11478900e-02  2.77392231e-02  4.16600406e-02 -1.72553547e-02\n",
      " -2.20398642e-02  3.47720981e-02  2.04981696e-02  1.11271059e-02\n",
      "  1.53777916e-02 -7.84212500e-02 -4.76050489e-02 -1.80646982e-02\n",
      " -2.64949817e-03  9.62796621e-03  3.99309807e-02  2.76857372e-02\n",
      " -5.62517531e-02  1.58320963e-02  8.57149623e-03 -6.61209598e-02\n",
      " -1.29279029e-02 -2.75374912e-02 -2.73725251e-04 -1.82666220e-02\n",
      "  1.19144162e-02 -1.70310792e-02 -3.33804041e-02  7.49145299e-02\n",
      "  1.17980363e-02  7.80725554e-02 -3.94509882e-02  4.34103906e-02\n",
      " -6.44988045e-02  5.15319705e-02  1.50570972e-03 -1.96008012e-02\n",
      "  3.67573798e-02  2.49757878e-02  2.43373588e-02  7.76672037e-03\n",
      "  8.23159330e-03 -2.38803905e-02 -2.43983753e-02  1.01570543e-02\n",
      " -6.49578171e-03 -2.26200242e-02 -6.43210188e-02 -5.85809373e-33\n",
      "  5.72300516e-03 -3.05973683e-02 -3.97941284e-02 -2.75348444e-02\n",
      " -3.82245257e-02 -5.70884794e-02  3.90184112e-02  2.50704996e-02\n",
      "  5.63412532e-03  1.47009920e-02  1.54906986e-02 -2.82354429e-02\n",
      " -3.30793625e-03 -1.65408570e-02  5.01762852e-02 -3.14617939e-02\n",
      "  4.43916917e-02 -1.14849471e-02  9.43833496e-03 -1.47571256e-02\n",
      " -1.40557261e-02  4.11555462e-04  3.25406231e-02  3.85502428e-02\n",
      "  3.99366692e-02  4.05447334e-02  6.32582754e-02 -1.42610576e-02\n",
      "  4.42889370e-02  3.41823958e-02  2.03564836e-04 -3.84817496e-02\n",
      " -2.23850142e-02 -1.92972613e-04  1.08099012e-02  6.29928857e-02\n",
      " -4.04752605e-02 -5.48928268e-02 -2.58665979e-02  3.75302061e-02\n",
      " -5.99690014e-03 -5.90909906e-02  4.43671383e-02 -4.23974618e-02\n",
      " -3.08833700e-02 -6.95434511e-02  4.37683277e-02  7.59853888e-03\n",
      "  2.81342026e-02  2.10340694e-02 -5.87086752e-02  6.04338653e-04\n",
      " -1.15476539e-02  1.26211336e-02  3.59117426e-03 -3.30250710e-02\n",
      "  4.99690771e-02  5.28940633e-02  2.40658373e-02  5.42520173e-03\n",
      " -1.01914175e-01  1.02941936e-03 -6.09651208e-02 -1.93752535e-02\n",
      "  1.88033786e-02  1.38115659e-02  5.69404513e-02 -2.24382058e-02\n",
      "  6.04909053e-03 -5.67644052e-02  3.10505228e-03  1.35167344e-02\n",
      "  9.48604569e-03  9.58835764e-04 -1.49123780e-02  5.22852503e-02\n",
      " -3.10254414e-02 -4.53669317e-02  1.41081056e-02  1.99068021e-02\n",
      " -2.84266677e-02  3.74705233e-02 -2.82629710e-02 -3.09950439e-03\n",
      "  6.50089756e-02  4.12673168e-02 -7.24415854e-03 -1.28572807e-02\n",
      " -6.20873123e-02 -2.51292214e-02  2.26080250e-02 -7.60199642e-03\n",
      " -2.05126163e-02  3.61304879e-02 -3.47006433e-02  5.85581511e-02\n",
      " -2.35079415e-02 -2.36007385e-02 -2.93973349e-02  2.77464483e-02\n",
      " -3.03294454e-02  3.50275598e-02  1.95699073e-02 -9.48888133e-04\n",
      " -2.28838138e-02 -2.76688300e-03 -2.84795873e-02  2.48472914e-02\n",
      "  3.78585490e-03  8.71540885e-03 -1.25125647e-02  2.02094764e-02\n",
      "  6.69893250e-02  3.83571759e-02  4.20986116e-02  3.21502946e-02\n",
      "  5.06816339e-03  2.82208044e-02 -4.37153764e-02 -5.24876900e-02\n",
      "  2.33595334e-02  4.01501320e-02 -5.28206378e-02 -1.88823212e-02\n",
      "  2.65419278e-02 -3.76599729e-02 -1.30796004e-02  3.60551365e-02\n",
      " -8.52108672e-02  1.03724552e-02 -5.09973103e-03 -2.75096409e-02\n",
      "  1.98919423e-07 -4.80021760e-02 -2.81328079e-03 -5.49867079e-02\n",
      "  5.07247783e-02 -5.01032099e-02  3.99160907e-02  1.22621255e-02\n",
      "  5.58770373e-02  1.81159265e-02  7.31264800e-02  3.04164700e-02\n",
      " -1.85559541e-02  6.41402453e-02 -3.08568124e-03 -9.02264751e-03\n",
      " -2.17575543e-02  7.57232634e-03  1.21865105e-02  8.79124645e-03\n",
      " -4.37642224e-02 -2.09047329e-02  8.48707929e-03  6.55811876e-02\n",
      "  5.24271801e-02  2.16284464e-03  9.67016723e-03  4.50440198e-02\n",
      " -6.29814342e-02  1.70640498e-02  3.81360762e-02  3.27997021e-02\n",
      "  1.73394755e-02 -3.52188908e-02 -2.37623602e-02 -6.45277500e-02\n",
      " -2.38861050e-02  2.92503722e-02 -1.90313943e-02 -9.24785528e-03\n",
      "  9.03677046e-02 -2.22485978e-02  7.60711059e-02 -3.77963670e-02\n",
      "  2.71167047e-02 -4.67768405e-03 -2.44298037e-02 -3.81839052e-02\n",
      "  9.57340654e-03 -4.68689948e-02  1.88797805e-02 -7.61640146e-02\n",
      "  3.02860904e-02 -3.40487435e-02  2.00572014e-02  6.23896718e-03\n",
      "  1.93612110e-02  5.93664087e-02  1.79113622e-03  4.11414281e-02\n",
      " -2.39268448e-02 -3.90329584e-02  1.00109674e-01  2.32497952e-03\n",
      "  4.22791950e-02  3.00961547e-02  3.52622494e-02 -1.95103362e-02\n",
      "  8.62984414e-35 -1.43457614e-02 -2.40049846e-02 -5.96125936e-03\n",
      "  1.58402491e-02 -4.83821593e-02 -2.64609400e-02  3.89628783e-02\n",
      "  1.60151012e-02  5.20297848e-02  1.09243754e-03 -4.58407439e-02]\n",
      "\n",
      "Sentence: Kobe is a great player\n",
      "Embeddings: [-2.82118525e-02 -9.04116780e-03  1.47323152e-02 -9.61336866e-03\n",
      "  6.27707643e-03 -9.59475152e-03 -1.23444218e-02 -1.73035599e-02\n",
      " -2.20347997e-02  2.16303603e-03 -3.87667231e-02  3.85243781e-02\n",
      "  2.45300960e-02 -4.04894985e-02 -3.95844830e-03  9.28172749e-03\n",
      "  3.49956192e-02  4.87582497e-02  1.20649815e-01  2.80728042e-02\n",
      "  2.89687999e-02 -1.19733755e-02  3.87907512e-02  6.53742161e-03\n",
      " -1.24635538e-02 -2.27510203e-02  3.98658402e-02 -6.08220808e-02\n",
      " -1.95839498e-02  1.09908544e-02 -1.03089973e-01 -2.95806639e-02\n",
      " -6.17376305e-02 -5.18394448e-02  1.39980489e-06  6.38066325e-04\n",
      "  6.61658347e-02 -7.09913496e-04  1.86926015e-02  7.20426627e-03\n",
      " -3.76049280e-02 -1.00609511e-02  7.16739986e-03 -5.19050509e-02\n",
      "  4.00629733e-03  4.50971946e-02  3.91169637e-02  6.94102943e-02\n",
      "  2.56250296e-02 -1.99230183e-02  4.82478105e-02 -4.29571085e-02\n",
      "  1.74177699e-02 -3.12592611e-02 -3.52522880e-02  4.95111495e-02\n",
      "  6.21278062e-02  2.52808910e-02 -1.31634632e-02 -1.07298335e-02\n",
      " -2.16147285e-02 -2.07273830e-02 -5.46170846e-02 -2.77616605e-02\n",
      "  1.09067574e-01 -3.34125645e-02  4.00532484e-02  3.29329781e-02\n",
      "  6.67546242e-02  1.51396133e-02 -3.45993973e-02  2.58169007e-02\n",
      "  5.16696926e-03 -7.58178439e-03  3.75934839e-02 -6.08188473e-02\n",
      " -1.54259067e-03 -1.02525670e-02  7.95563124e-03 -1.65775921e-02\n",
      " -5.00032119e-02 -2.80231726e-03  2.29841471e-02 -3.46449390e-02\n",
      " -7.64422119e-03 -2.04899944e-02  2.09594779e-02 -1.11607567e-03\n",
      " -5.63489795e-02 -5.06420713e-03 -3.32728699e-02 -3.53483371e-02\n",
      " -8.00071575e-04  3.41142970e-03  1.47614861e-02  1.11595849e-02\n",
      "  1.52857946e-02  6.83271065e-02 -2.96210833e-02 -8.22365358e-02\n",
      "  4.39710841e-02  1.69113986e-02  4.83271070e-02 -9.88003053e-03\n",
      " -5.61211538e-03  7.20386356e-02 -7.80361937e-03 -2.69338265e-02\n",
      "  1.48752509e-02  1.96265038e-02 -1.62536465e-02  1.33487368e-02\n",
      "  3.58128385e-03  1.26843108e-02 -1.46175195e-02  3.03835869e-02\n",
      " -1.95606072e-02  3.26657994e-03 -3.08693275e-02 -1.12716267e-02\n",
      "  7.42430193e-03 -6.32353574e-02 -1.34774437e-02  1.71646327e-02\n",
      " -4.03368175e-02  7.90505763e-03 -9.64638144e-02  1.63418576e-02\n",
      " -6.33923262e-02 -1.79759581e-02 -3.19660008e-02 -1.47585357e-02\n",
      "  9.87625774e-03  3.99344414e-02  4.94580306e-02 -4.64827120e-02\n",
      "  1.48687232e-02 -4.51283231e-02  2.72384249e-02  4.32527922e-02\n",
      " -4.22702916e-02 -1.53702851e-02  1.19535374e-02 -2.87613980e-02\n",
      "  3.20154242e-02  2.27719657e-02  3.00138909e-02 -3.54787195e-03\n",
      " -5.46104182e-03  6.51898012e-02  3.92587809e-03 -3.91748026e-02\n",
      "  5.60619449e-03 -3.01766135e-02  1.56902578e-02 -2.87288185e-02\n",
      "  3.96909714e-02 -5.35050519e-02  2.47440636e-02 -7.01344013e-02\n",
      " -2.63235141e-02 -2.77276076e-02  6.12143101e-03  1.15330685e-02\n",
      " -6.91011325e-02 -1.17060225e-02  9.72461421e-03  1.41950126e-03\n",
      " -4.87588756e-02  4.43486832e-02 -3.78297493e-02  6.91233529e-03\n",
      " -8.33775923e-02  4.74074408e-02  2.28677243e-02 -3.94263342e-02\n",
      " -6.15095086e-02  4.55096290e-02 -3.30302306e-03  2.56435908e-02\n",
      "  8.00985470e-03 -4.79364693e-02 -2.73989365e-02  3.70797142e-02\n",
      "  9.93705392e-02  6.37206342e-03 -1.06701523e-01  5.32008521e-02\n",
      "  3.71813811e-02 -5.29544279e-02 -1.70130078e-02  2.94457506e-02\n",
      " -3.90315577e-02 -3.56740206e-02  2.04433147e-02  1.75124090e-02\n",
      "  4.16667722e-02  1.08828716e-01 -4.95580630e-03  8.94688070e-03\n",
      " -2.46939948e-03 -1.05523588e-02  2.07498707e-02 -8.01233649e-02\n",
      "  1.71008855e-02  4.01311256e-02  4.60258834e-02 -1.14087006e-02\n",
      "  4.00634259e-02 -5.61336800e-03 -4.11555693e-02  7.71431299e-03\n",
      "  5.06581925e-03 -4.12896983e-02  3.78354304e-02  1.54614006e-03\n",
      "  5.99360988e-02  2.62340009e-02  1.23164458e-02  3.02056801e-02\n",
      " -1.08005842e-02 -5.91418631e-02  8.70986730e-02  1.38603514e-02\n",
      " -1.33855473e-02 -5.45361787e-02  3.43634747e-02 -6.27224222e-02\n",
      "  2.84420941e-02  2.98906434e-02 -4.49189451e-03  4.98954169e-02\n",
      " -2.95415544e-03  1.65495798e-02 -1.56008527e-02  6.91428632e-02\n",
      " -3.61566097e-02 -1.58006779e-03 -3.89778428e-02 -2.73550469e-02\n",
      "  4.78531327e-03 -1.26937227e-02  3.80774960e-02 -2.90945396e-02\n",
      " -1.94594171e-02  1.70382753e-03  1.00991301e-01  2.95712985e-02\n",
      "  2.35348959e-02 -4.27234247e-02 -1.85795259e-02 -4.26407205e-03\n",
      " -3.61659867e-03  2.95286458e-02  1.83480419e-02 -3.23805735e-02\n",
      "  7.29176924e-02  6.82157278e-02  6.90440089e-02 -2.12516617e-02\n",
      "  4.05838108e-03  7.54929613e-04 -2.10751174e-03  1.25279594e-02\n",
      "  6.54754490e-02 -1.36684850e-02  6.78714737e-03 -3.62858437e-02\n",
      "  3.79247479e-02  3.14189382e-02  4.60656174e-03 -2.43665110e-02\n",
      "  3.89632620e-02  2.24890783e-02 -2.40311045e-02 -9.78498347e-03\n",
      " -2.86865048e-02  3.68277617e-02 -3.82541530e-02 -5.26750460e-03\n",
      "  5.13897371e-03 -1.19900536e-02 -1.80793144e-02 -1.24877589e-02\n",
      "  3.73000801e-02  4.42280574e-03 -2.99135339e-03  2.56087128e-02\n",
      " -3.43990773e-02 -2.75580902e-02 -1.23009980e-02 -4.25507203e-02\n",
      "  3.73038538e-02  1.06519489e-02  1.48978932e-02  9.28254146e-03\n",
      " -3.52154076e-02  2.17907410e-02 -3.42823565e-03 -9.03730839e-03\n",
      "  5.39099015e-02 -8.29852745e-02  6.56244457e-02  8.94746277e-03\n",
      "  5.00975326e-02 -9.76906810e-03 -2.28925515e-02  8.36866498e-02\n",
      "  3.62874642e-02  5.69830928e-03  1.92582812e-02  1.28917573e-02\n",
      " -3.86314280e-03 -6.11638501e-02  2.44999137e-02 -3.23809907e-02\n",
      "  1.63926017e-02 -9.64769255e-03 -3.52175348e-02 -1.06267415e-01\n",
      " -1.56528968e-02  2.80204713e-02 -1.32153230e-02 -4.92548710e-03\n",
      "  2.49151178e-02  9.04063229e-03  9.04199481e-03  2.01389510e-02\n",
      " -2.26178877e-02  3.50510590e-02  1.52031761e-02 -2.52178777e-03\n",
      "  9.92886163e-03  2.95503978e-02  4.89426702e-02  1.53732467e-02\n",
      "  5.21792695e-02 -9.58876461e-02 -9.95557010e-03 -3.37995030e-02\n",
      "  3.08098812e-02 -9.12985113e-03 -7.63334474e-03  7.64195994e-02\n",
      " -7.72487894e-02 -3.74733508e-02  1.38439322e-02 -7.56263360e-03\n",
      " -9.73477364e-02 -3.08663361e-02  6.25444623e-03 -1.05692968e-01\n",
      "  7.25860102e-03 -5.22184744e-02  4.41941470e-02  2.27540806e-02\n",
      " -7.09983893e-03 -2.43348777e-02 -3.79495211e-02 -8.58548377e-03\n",
      " -2.73742508e-02  6.04124181e-02 -3.96131985e-02  3.12218890e-02\n",
      "  1.25986291e-02 -3.82516580e-03  1.01403436e-02  1.27013018e-02\n",
      " -1.97142009e-02  1.89646147e-02  6.22661747e-02 -2.38338355e-02\n",
      " -8.36420432e-02  4.03325297e-02 -3.96144198e-04  2.23353859e-02\n",
      " -2.01560557e-03 -5.02762618e-03 -3.59465964e-02 -3.94813977e-02\n",
      " -2.51413006e-02  1.31257251e-02 -6.94100857e-02  8.81774258e-03\n",
      " -7.61652645e-03 -1.36984792e-02  3.94006819e-02  1.84967853e-02\n",
      " -1.53238093e-02  4.31566760e-02  3.45505960e-02  1.75086304e-03\n",
      " -2.99360827e-02 -6.11203499e-02  5.21622002e-02 -1.88613851e-02\n",
      "  1.09453946e-02 -8.11145362e-03  1.76527502e-03 -3.76036726e-02\n",
      " -4.08613868e-02  4.67633121e-02 -5.39064361e-03  5.03118224e-02\n",
      " -6.63680211e-03 -3.09437048e-02  3.13354656e-02  7.75672272e-02\n",
      "  3.44914058e-03  1.49875488e-02 -4.24690843e-02  4.92445678e-02\n",
      "  1.93172190e-02 -2.29831989e-04 -3.89764011e-02 -2.44477205e-02\n",
      "  1.11007839e-02 -7.65819326e-02  1.51059944e-02  2.37614308e-02\n",
      " -3.46031897e-02 -2.33574919e-02  2.51610354e-02  1.60388388e-02\n",
      " -1.90702248e-02  7.37922871e-03 -1.59644615e-02 -7.31789833e-03\n",
      " -2.46850178e-02 -1.45876557e-02  2.87357830e-02 -1.73507910e-02\n",
      "  2.34455359e-03 -1.31595992e-02  3.12542915e-02 -3.82079519e-02\n",
      "  2.27644667e-03 -3.83421080e-04  1.74544323e-02 -3.13523635e-02\n",
      " -3.45121138e-02 -2.45939847e-02 -3.00451070e-02  8.89339671e-03\n",
      " -1.82946362e-02 -2.78982930e-02 -8.96145776e-03  1.14380512e-02\n",
      "  4.77330963e-04  2.53427271e-02 -4.17809337e-02  1.10710692e-02\n",
      "  2.56903637e-02  6.13985658e-02 -1.15502430e-02  6.36300072e-04\n",
      " -6.48147333e-03  1.15178600e-02  2.95234546e-02  2.09400505e-02\n",
      "  7.11889472e-03  4.78506275e-03 -2.31199292e-03  2.62122769e-02\n",
      "  2.70864996e-03  2.30019484e-02  6.66228607e-02  2.11886484e-02\n",
      " -2.70784292e-02 -1.65114067e-02 -6.92118704e-02  1.53120989e-02\n",
      "  2.85270857e-03  1.39746005e-02  1.71007812e-02 -5.82010336e-02\n",
      " -3.11968513e-02 -7.39365667e-02 -3.21909301e-02 -4.75111790e-02\n",
      "  3.00381090e-02  3.97835635e-02  2.30940878e-02  4.62270528e-03\n",
      " -1.05134901e-02  2.00438057e-03 -2.46795956e-02  3.19098122e-02\n",
      "  1.33889518e-03 -4.39205300e-03  1.65139567e-02  6.40924647e-02\n",
      " -5.82538061e-02  6.05147071e-02 -4.27788720e-02 -2.02401169e-02\n",
      " -1.04733249e-02  2.28739064e-02  4.09436822e-02 -6.77453279e-02\n",
      " -5.72763430e-03 -2.64745932e-02 -1.62202679e-02 -5.19788936e-02\n",
      "  5.22521697e-03 -6.45656511e-02  2.64531914e-02  1.57226156e-02\n",
      " -2.42822468e-02  7.40127871e-03  3.46643478e-02  4.14328165e-02\n",
      " -4.67906930e-02  6.23079529e-03  1.13450028e-02  3.67483348e-02\n",
      "  3.26659977e-02 -7.60764210e-03 -2.63546519e-02  2.62175519e-02\n",
      " -1.88959613e-02  3.50738913e-02  5.12670577e-02 -2.13443339e-02\n",
      " -5.60437925e-02 -4.98619489e-02  2.80338340e-02 -3.74242403e-02\n",
      " -2.94337291e-02 -7.22687989e-02 -5.77903986e-02 -3.44954319e-02\n",
      " -7.98855498e-02  7.61008851e-05  1.07952894e-03  4.77356911e-02\n",
      "  1.07565578e-02  1.33897141e-02 -9.36673488e-03 -6.32448262e-03\n",
      " -3.25812511e-02  7.75129348e-03  2.00480595e-02 -4.41260636e-03\n",
      "  3.40627879e-02  5.22447564e-02 -1.00611029e-02  3.15408148e-02\n",
      "  1.62822902e-02 -4.52730097e-02 -1.84213761e-02 -6.38789823e-03\n",
      " -5.94686456e-02  6.42821472e-03  2.95223948e-02 -4.51839421e-33\n",
      "  2.26026662e-02  6.71956083e-03  3.37767205e-03 -1.45988939e-02\n",
      " -4.23202887e-02 -7.68176317e-02  9.29052592e-04  7.94126187e-03\n",
      " -1.65877659e-02  4.04102281e-02 -1.14784846e-02  5.48529774e-02\n",
      "  1.66666638e-02  1.22464914e-02  4.35367823e-02 -4.47990149e-02\n",
      "  3.11674122e-02 -6.85791904e-03 -1.47530362e-02  2.86404695e-02\n",
      " -1.49253923e-02 -1.81328338e-02 -2.42196769e-02 -3.69186234e-03\n",
      "  7.37573430e-02 -1.49182826e-02 -8.79462156e-03  2.17344146e-02\n",
      "  2.43539102e-02  2.03567781e-02 -8.33725650e-03  6.66982308e-03\n",
      " -5.00087347e-03  3.54147777e-02 -1.43355783e-02  6.73355758e-02\n",
      " -3.37242484e-02  1.08639598e-02 -4.11371104e-02  3.27677019e-02\n",
      " -1.65638868e-02  2.61335149e-02  1.12389931e-02 -2.24228892e-02\n",
      "  3.83957895e-03  4.06702757e-02 -1.71461590e-02 -3.22076096e-03\n",
      "  3.89411650e-03 -2.19590962e-02 -3.80509682e-02 -2.89139198e-03\n",
      " -2.14842986e-02  4.38692942e-02 -5.94137274e-02 -4.37597781e-02\n",
      " -1.07475212e-02  3.90630439e-02 -7.50316030e-05  4.13619308e-03\n",
      " -3.51980552e-02 -5.86198680e-02 -2.78871264e-02  4.57842276e-03\n",
      "  6.45194873e-02  8.75054020e-03  4.62152883e-02 -2.66618282e-02\n",
      "  4.59132977e-02 -5.38304523e-02 -2.25949679e-02  3.62461135e-02\n",
      "  3.68288788e-03  9.47648734e-02 -9.12569184e-03  2.52024680e-02\n",
      "  4.17721234e-02 -2.96226088e-02 -5.21049788e-03  3.02704703e-02\n",
      " -2.70659309e-02  2.51187775e-02 -6.25919551e-02  8.09839834e-03\n",
      "  2.79025212e-02 -2.19831802e-02  1.08336164e-02  1.51417851e-02\n",
      "  2.06056926e-02 -5.37605621e-02 -6.22554310e-03 -4.66736332e-02\n",
      "  1.38660902e-02  8.99282005e-03  9.43289232e-03  2.00360399e-02\n",
      " -3.32086459e-02 -4.92762215e-02 -2.08499376e-02 -1.68992335e-03\n",
      " -2.00822223e-02  2.65767053e-02  1.86196025e-02 -1.90073941e-02\n",
      " -2.28595617e-03  1.65688246e-02 -2.86864061e-02 -1.47141684e-02\n",
      " -4.36687982e-03 -8.86137970e-03 -4.03925665e-02 -3.34767029e-02\n",
      " -3.54132731e-03  5.10584610e-03 -1.61204133e-02  1.39268450e-02\n",
      "  1.11534148e-02  1.49048911e-02 -2.62586474e-02  2.55388841e-02\n",
      " -1.07759684e-02  1.32134538e-02 -5.14362976e-02  1.86543178e-03\n",
      "  1.47883408e-02 -8.26745946e-03  5.26817841e-03  2.96338946e-02\n",
      " -3.48620899e-02 -2.37120446e-02 -3.87853459e-02 -7.96373412e-02\n",
      "  2.11507157e-07  1.07965916e-02  3.41437608e-02 -5.92588484e-02\n",
      " -8.03548563e-03 -3.82074974e-02  1.11587957e-01 -2.19877753e-02\n",
      "  1.21182222e-02  4.94650332e-03  9.92240384e-02  6.70098662e-02\n",
      " -3.26306745e-02  4.85678762e-03  9.97680891e-03 -1.38606904e-02\n",
      " -1.59668140e-02  4.55764420e-02 -9.50156376e-02  2.01130491e-02\n",
      " -5.36803044e-02  1.73400547e-02 -4.00989689e-02  8.62210337e-03\n",
      "  1.32863978e-02 -2.67898515e-02 -7.72122815e-02  6.46701530e-02\n",
      " -1.82850584e-02  2.01686285e-02  1.79848145e-03  7.39833117e-02\n",
      " -4.67263795e-02  2.34149620e-02  2.79222131e-02 -5.17243035e-02\n",
      " -2.94224899e-02 -3.91042866e-02  5.51042743e-02  8.90349736e-04\n",
      "  5.51502034e-02  1.83935389e-02 -1.31269088e-02 -2.36003771e-02\n",
      "  4.59791571e-02 -1.05446130e-02  2.21048556e-02 -5.44401482e-02\n",
      " -5.71312606e-02 -6.92302957e-02  3.45594175e-02  3.31442128e-03\n",
      "  2.77298000e-02 -6.72984496e-03  5.24469055e-02  8.64215568e-03\n",
      " -2.20127609e-02  2.70857774e-02  2.48317178e-02  7.83131737e-03\n",
      " -7.51938224e-02 -1.04140248e-02  7.12444782e-02  7.11087286e-02\n",
      "  7.08477497e-02  1.40701272e-02  6.24108538e-02  3.48708108e-02\n",
      "  7.80911375e-35 -1.22509981e-02 -2.13047862e-02  5.00691980e-02\n",
      "  1.84837710e-02 -4.78601642e-02 -4.66456520e-04 -1.69643741e-02\n",
      "  1.81279313e-02  3.87187935e-02  7.45013505e-02 -1.97942164e-02]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model=SentenceTransformer(model_name_or_path='all-mpnet-base-v2', device='cpu')\n",
    "\n",
    "#Create a list of Sentences\n",
    "sentences=[\"I like football\",\"I like basketball\", \"Kobe is a great player\"]\n",
    "\n",
    "#Sentences are encoded/embedded by calling model.encode()\n",
    "embeddings=embedding_model.encode(sentences)\n",
    "embeddings_dict=dict(zip(sentences, embeddings))\n",
    "\n",
    "#See embeddings\n",
    "for sentence, embeddings in embeddings_dict.items():\n",
    "    print(f\"Sentence: {sentence}\")\n",
    "    print(f\"Embeddings: {embeddings}\")\n",
    "    print(\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cb9e69",
   "metadata": {},
   "source": [
    "Woah! That's a lot of numbers.\n",
    "\n",
    "How about we do just once sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80e9dd69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Who is Michael Jordan?\n",
      "Embedding:\n",
      "[ 1.48610771e-03 -1.29408650e-02  4.12214510e-02  1.48524977e-02\n",
      "  4.33810474e-03  1.77816706e-04  1.77243222e-02 -1.45564685e-02\n",
      "  3.38754840e-02 -3.48900668e-02  2.58417353e-02  2.15714537e-02\n",
      "  1.22249816e-02  2.01746691e-02  3.11459322e-02 -1.97694656e-02\n",
      "  2.88256221e-02 -2.19796542e-02  1.69615056e-02 -6.30995631e-03\n",
      " -3.76892760e-02  3.13616637e-03  1.31576005e-02  4.23933007e-02\n",
      " -6.79306760e-02 -3.42432857e-02  1.42761124e-02 -1.04357312e-02\n",
      " -3.40646617e-02  2.10747235e-02 -5.73627837e-02 -3.49448919e-02\n",
      "  3.54876113e-03 -5.57608232e-02  1.40041789e-06  8.85181408e-03\n",
      "  5.87321296e-02 -1.26579041e-02  4.14434522e-02 -3.53717878e-02\n",
      " -3.66200916e-02 -4.22541238e-02 -6.18494349e-03  2.17272546e-02\n",
      " -1.62388813e-02 -3.43839340e-02  1.98135171e-02 -2.18353979e-02\n",
      " -1.34257283e-02  9.53534525e-03  4.17782478e-02 -1.07229194e-02\n",
      "  3.07925977e-02 -3.29672098e-02 -3.48641463e-02 -1.76475141e-02\n",
      "  2.64758412e-02  5.72366677e-02 -9.53142047e-02 -3.24030854e-02\n",
      " -1.19644981e-02  2.52823140e-02 -6.15231581e-02 -2.27554180e-02\n",
      "  4.81360517e-02 -7.98497535e-03 -1.69439353e-02  2.49707457e-02\n",
      "  2.03291439e-02  1.36252111e-02 -4.10298333e-02 -2.11949591e-02\n",
      "  4.10123952e-02  9.01053101e-02  2.44443491e-02  4.35017273e-02\n",
      "  4.66371700e-02  6.62337914e-02  4.01614159e-02 -3.96601856e-02\n",
      " -2.29190756e-02  3.24564204e-02  2.53425986e-02 -1.19209150e-02\n",
      " -2.04656832e-02  1.90375056e-02 -6.77721715e-03  2.04240903e-02\n",
      " -9.92860645e-03  1.03868628e-02  7.98518807e-02 -5.79214059e-02\n",
      "  4.27643545e-02  6.99010715e-02 -2.16403287e-02 -3.93934846e-02\n",
      " -3.51162348e-03 -9.64881200e-03 -6.95140660e-02 -6.51811361e-02\n",
      "  7.20926421e-03  4.76903617e-02  1.18859455e-01 -7.05361075e-04\n",
      "  2.89608035e-02 -1.77572668e-03 -9.18025710e-03 -5.14665544e-02\n",
      " -3.56493071e-02 -3.49588543e-02 -6.38287514e-02  1.71572538e-04\n",
      "  5.29551739e-03  6.73261732e-02 -6.54115528e-03  7.80281378e-03\n",
      "  2.52764323e-03  3.05105504e-02  8.98415223e-03 -5.13392687e-03\n",
      " -1.20104469e-01 -4.69145291e-02  1.79743220e-03 -1.35557754e-02\n",
      " -5.18565578e-03 -2.15638019e-02 -8.21015239e-02 -3.08913905e-02\n",
      " -3.13958968e-03  1.55976368e-02 -1.86668057e-02  2.17851363e-02\n",
      " -2.78169829e-02  2.23369664e-03  2.61427835e-02  1.23035908e-01\n",
      "  9.41851083e-03 -3.34113203e-02  9.52900213e-04 -1.14723435e-02\n",
      " -2.54388768e-02  1.74711999e-02 -1.27325440e-02  2.34327801e-02\n",
      " -6.50561322e-03 -3.15056294e-02  4.00204957e-02 -1.75204743e-02\n",
      " -3.21819745e-02  8.31385888e-03  3.97440139e-03 -1.52966502e-04\n",
      " -2.80184150e-02  4.70169121e-03  1.46974192e-03 -1.13325650e-02\n",
      " -5.72214834e-03 -5.99587671e-02  5.44262910e-03 -2.47438159e-02\n",
      " -6.62134821e-03  1.02907687e-03  5.68696745e-02  1.23998541e-02\n",
      " -2.32839435e-02 -5.25116771e-02  3.73313986e-02 -5.94004849e-03\n",
      " -7.77726471e-02 -1.93003076e-03 -1.13197416e-02 -2.04954166e-02\n",
      " -8.95634759e-03  3.67158912e-02  1.15514360e-03 -1.19225848e-02\n",
      " -8.81869253e-03 -1.10295825e-02  2.66812965e-02  1.41805736e-02\n",
      "  6.80700392e-02 -9.18679386e-02  2.78964471e-02  8.84323660e-03\n",
      "  7.79901743e-02  5.48136719e-02 -3.67508307e-02  5.50118126e-02\n",
      " -3.00299637e-02 -3.53143439e-02  5.96881770e-02 -3.39656696e-02\n",
      " -1.13096898e-02  4.43609804e-03  2.77203578e-03 -2.02367269e-02\n",
      "  3.51484232e-02  1.13079078e-01 -4.63342369e-02  3.88259962e-02\n",
      " -1.86476819e-02  1.12971114e-02 -5.73386326e-02 -7.41641670e-02\n",
      " -9.45647154e-03  4.54243599e-03  5.55924699e-02 -1.12095140e-02\n",
      " -1.11085467e-01 -6.33016080e-02 -2.54527386e-02  1.68558322e-02\n",
      "  1.55172544e-02  1.64076276e-02  4.97103445e-02  7.23149953e-03\n",
      "  8.70617107e-02 -1.03301434e-02  1.74286310e-02  4.10450138e-02\n",
      " -1.77198164e-02  5.57743795e-02  8.54194760e-02 -3.22293937e-02\n",
      "  6.02553991e-05 -1.82111468e-02  4.18002494e-02 -4.54486255e-03\n",
      "  6.06909255e-03  4.72029336e-02  3.51321287e-02 -4.84455330e-03\n",
      " -8.85336567e-03 -4.43408405e-03  1.60441478e-03 -3.50646228e-02\n",
      "  1.70772728e-02 -1.76425651e-02  4.87591587e-02 -5.64308427e-02\n",
      "  2.70943157e-02  9.37856659e-02  1.90650765e-02 -4.21900600e-02\n",
      "  3.07260361e-02  3.75022180e-02  7.02630058e-02 -2.64965128e-02\n",
      "  1.09423827e-02 -8.16937909e-03 -7.22069293e-02 -1.45505983e-02\n",
      "  1.00732800e-02  2.15294864e-02 -1.19404569e-02  6.15777040e-04\n",
      " -3.28590050e-02  1.23185180e-02  5.20523004e-02 -3.01617682e-02\n",
      " -7.32690329e-03 -5.65031655e-02 -4.21946198e-02 -3.29130031e-02\n",
      "  5.01795970e-02 -2.53276937e-02  4.40251455e-02 -4.39979881e-03\n",
      "  2.82253623e-02 -1.59562360e-02  3.60585116e-02  2.26648971e-02\n",
      "  2.63986234e-02 -4.12636809e-03 -2.01933365e-02  5.60454391e-02\n",
      " -7.75078610e-02 -5.12632094e-02 -5.54347597e-02  3.01038548e-02\n",
      " -7.80607946e-03 -3.61765764e-04 -3.65015119e-02 -2.78929621e-02\n",
      "  1.64858084e-02  3.03925737e-03 -2.06075367e-02  4.35701311e-02\n",
      " -1.78232528e-02 -5.46556376e-02 -5.98938763e-02 -6.10608198e-02\n",
      "  6.46756729e-03  4.40894030e-02  3.64730768e-02  4.72572893e-02\n",
      "  3.86716537e-02 -5.00394031e-02 -2.08262820e-02  2.98219528e-02\n",
      "  3.72984037e-02 -9.00001079e-02  6.22749291e-02  6.98580500e-03\n",
      " -6.07004343e-03 -2.42993217e-02 -9.38536040e-03  4.33174968e-02\n",
      " -1.79818757e-02 -3.64482217e-02 -1.72035582e-02 -8.34737718e-03\n",
      " -1.31905237e-02 -2.95930804e-04  3.85857932e-02 -9.81796999e-04\n",
      " -2.61821039e-02 -7.28517829e-04 -1.06650060e-02  1.78858545e-02\n",
      " -5.98301506e-03  4.11062464e-02 -9.90627799e-03 -1.74736080e-04\n",
      "  2.50294413e-02  6.35222942e-02  1.01676229e-02 -1.86757604e-03\n",
      " -4.39276285e-02  4.25625499e-03 -2.24861875e-02 -5.55245243e-02\n",
      "  6.55782828e-03  5.38155921e-02  5.75981550e-02 -6.84882561e-03\n",
      "  2.97433184e-03  1.43657567e-03 -2.80391779e-02 -4.51723859e-02\n",
      "  9.31319222e-03  3.75874452e-02  1.89428888e-02  3.38583253e-03\n",
      " -8.31136405e-02 -3.62538919e-02  1.80430543e-02  3.00674383e-02\n",
      " -1.07328661e-01 -6.29787371e-02  2.53579486e-02 -9.29859933e-03\n",
      "  6.56657480e-03 -6.20015524e-02 -8.23128223e-03  8.50402378e-03\n",
      " -2.25217510e-02 -2.71083023e-02  2.74793543e-02  1.93629321e-02\n",
      "  4.33571776e-03 -1.10191386e-02  4.87715472e-03  5.14216758e-02\n",
      "  4.71536331e-02  4.86804871e-03  1.91889517e-02  1.08595891e-02\n",
      " -1.00035267e-02  8.19580704e-02  5.31410351e-02 -4.26432565e-02\n",
      "  5.09817153e-04  3.44155878e-02 -3.05133294e-02  1.50111122e-02\n",
      "  2.24637613e-02 -1.90836079e-02 -9.49083362e-03 -1.36181144e-02\n",
      "  6.34553954e-02 -6.76329294e-03  1.62797179e-02  1.73307899e-02\n",
      " -1.11008985e-02  2.87627755e-03  5.11699542e-02 -2.72158720e-02\n",
      " -9.42742731e-03  1.36314938e-03  3.17385048e-02 -4.52426299e-02\n",
      " -9.61744320e-03  6.92484761e-03  8.02225713e-03 -3.26908119e-02\n",
      "  9.90094803e-03  1.32540818e-02 -7.30094034e-03  8.51809233e-03\n",
      " -1.30482751e-03 -1.08315074e-03  3.20030190e-02  3.14891315e-03\n",
      "  7.94534832e-02 -1.79487467e-02  9.97319631e-03 -1.22236216e-03\n",
      " -1.39302816e-02  7.44187832e-02  5.58349886e-04 -1.40934829e-02\n",
      " -1.53853185e-02 -5.09334691e-02  4.46641780e-02 -7.09955096e-02\n",
      " -1.63558349e-02 -8.56206417e-02  1.85677595e-02  3.36691644e-03\n",
      " -1.38039002e-03 -2.95924302e-03 -1.77954789e-02  2.98965313e-02\n",
      "  4.67825271e-02  9.37030651e-03 -5.01471721e-02 -4.45365235e-02\n",
      " -2.96059973e-03 -9.27638821e-03  2.03252863e-02 -1.26807680e-02\n",
      " -1.01856114e-02  3.61068957e-02 -2.54030097e-02 -8.86848569e-02\n",
      " -6.28453270e-02  3.06237880e-02  4.33166362e-02  5.73439188e-02\n",
      "  7.57530658e-03  2.18469594e-02 -7.64158890e-02 -7.38213956e-03\n",
      " -2.85439827e-02  1.04108443e-02 -8.18847585e-03  1.18531361e-02\n",
      "  1.85222160e-02 -4.33787256e-02 -9.30284988e-03  2.44053341e-02\n",
      "  7.35505344e-03  7.37771904e-03  1.11216668e-03  1.91687942e-02\n",
      " -4.16048244e-02  2.49515101e-02  4.07619476e-02 -4.55944724e-02\n",
      "  1.78680494e-02  8.00890103e-03  2.18390916e-02  5.56571111e-02\n",
      " -5.37003111e-03 -4.88528572e-02 -4.12863791e-02  3.19420770e-02\n",
      " -2.54704226e-02 -2.60110646e-02 -5.06797200e-03 -2.79912420e-05\n",
      "  5.73683158e-03  7.29488628e-03 -3.15863006e-02 -3.27526107e-02\n",
      " -2.30454765e-02 -4.34959568e-02  2.86551807e-02 -3.21001559e-02\n",
      " -1.47465756e-02 -3.90741415e-03 -1.27215767e-02 -1.60765015e-02\n",
      "  5.68523556e-02  1.45339621e-02 -5.22086769e-02  4.36322130e-02\n",
      " -4.24222648e-03  3.11892331e-02 -3.44944298e-02  1.36722103e-02\n",
      " -5.37388958e-02 -6.16377965e-02 -3.54708433e-02  5.34805432e-02\n",
      "  4.72623948e-03 -2.69309729e-02 -4.74975035e-02 -3.41986232e-02\n",
      " -5.67312166e-02  5.57270972e-03  1.33736962e-02  1.28663238e-02\n",
      " -3.54090333e-03 -1.49651933e-02  2.37671118e-02 -1.19584175e-02\n",
      "  1.44058047e-02  3.88698801e-02 -8.81305244e-03  1.49019090e-02\n",
      " -1.80756040e-02  3.95486727e-02  3.26493382e-02  1.92336943e-02\n",
      "  2.80066226e-02 -2.25521028e-02  1.01810405e-02  8.80745240e-03\n",
      " -1.19205717e-04  3.16090658e-02  1.57273524e-02 -1.03972657e-02\n",
      " -6.82643673e-04 -7.63202310e-02  1.36960847e-02 -3.44413817e-02\n",
      "  4.67066988e-02  3.15915681e-02 -7.37603158e-02 -4.48245704e-02\n",
      " -5.29918633e-02  5.88925835e-03  4.03932063e-03  1.44532830e-01\n",
      "  2.61326656e-02  9.76925045e-02  1.98891107e-02 -1.07663646e-02\n",
      " -5.94727099e-02 -2.61182971e-02  7.93977380e-02  3.59431803e-02\n",
      " -2.20083501e-02  5.50622493e-02 -9.93732177e-03  3.18289065e-04\n",
      "  4.19274494e-02 -2.13183314e-02 -3.88250649e-02  2.43681855e-02\n",
      " -5.51974811e-02 -9.42408480e-03  5.36436364e-02 -5.06284499e-33\n",
      "  3.40705104e-02  1.69876264e-04  1.59193613e-02  9.17442888e-02\n",
      " -6.93077520e-02  3.37244128e-03 -3.40593867e-02  2.90028453e-02\n",
      " -4.81807031e-02  2.16673240e-02  1.56244226e-02 -2.08207946e-02\n",
      "  2.95062866e-02  5.71270753e-03  1.68322250e-02 -1.68643035e-02\n",
      " -1.57535952e-02 -3.26036662e-03  3.73231694e-02  1.02282129e-02\n",
      " -2.51418687e-02 -2.47167312e-02 -6.67591393e-02  4.91437502e-02\n",
      "  6.79666316e-03 -1.89834423e-02 -1.18214702e-02  4.44414541e-02\n",
      " -4.71669436e-03 -2.16907822e-02 -2.23114365e-03 -2.34781243e-02\n",
      " -8.65652412e-03 -1.16623230e-02 -9.23517998e-03  1.56764314e-02\n",
      " -4.23814282e-02  3.44023742e-02 -5.84521070e-02  2.64999233e-02\n",
      " -2.74190363e-02 -2.25919709e-02  2.58905301e-03 -1.78657640e-02\n",
      " -1.94304492e-02 -6.06352510e-03 -4.87575270e-02 -7.54820835e-03\n",
      "  2.05440614e-02 -4.19459939e-02  5.61738038e-04 -8.45258124e-03\n",
      "  5.05178422e-03  7.15151615e-03  2.12985035e-02  1.39054516e-02\n",
      "  4.89404611e-03  3.11994199e-02  2.91483849e-02 -5.04316725e-02\n",
      " -7.00094476e-02 -3.53463292e-02 -2.65285596e-02  2.91448589e-02\n",
      " -2.62825526e-02 -3.21840052e-03  1.46810621e-01  4.90882341e-03\n",
      "  1.95240751e-02 -2.83215623e-02  1.74101461e-02 -2.94339862e-02\n",
      " -3.05857006e-02  5.88824041e-02 -4.16564867e-02  6.27255440e-03\n",
      " -1.38355896e-03  1.15800872e-02  5.94669301e-03 -4.86366032e-03\n",
      " -6.11484684e-02 -2.03677043e-02  1.79964956e-02  1.63885728e-02\n",
      "  3.21763637e-03  1.06688803e-02 -1.30005563e-02  2.44787093e-02\n",
      "  4.27046716e-02 -2.85113957e-02  4.27567288e-02  3.77678797e-02\n",
      "  1.15708290e-02 -1.33389737e-02  8.58629029e-03  7.15356600e-03\n",
      " -1.67310368e-02  6.23135408e-03  1.00359824e-02 -2.62450725e-02\n",
      " -3.26163247e-02  4.28309664e-02 -1.27257882e-02  1.41982352e-02\n",
      "  1.47050414e-02 -5.16086468e-04 -6.70432821e-02  1.01804445e-02\n",
      " -2.63758749e-02 -7.06704333e-04 -6.76540099e-03  7.02959578e-03\n",
      " -1.33639446e-03 -1.88417267e-02 -2.84316819e-02  2.41801776e-02\n",
      " -1.66141603e-03 -1.92303455e-03 -4.39022407e-02 -3.82206105e-02\n",
      "  1.63314096e-03  2.71879118e-02 -3.78967486e-02  2.36983784e-02\n",
      "  2.10203640e-02 -2.06805742e-03  1.12233683e-02  1.76181681e-02\n",
      " -5.66013157e-02  2.95262486e-02 -4.09061909e-02 -3.27560566e-02\n",
      "  2.07318521e-07  6.08254224e-02  1.94378886e-02 -8.13725516e-02\n",
      " -4.60809544e-02 -1.32105025e-02  4.13957126e-02 -1.72559209e-02\n",
      " -3.10975332e-02  3.60525362e-02  5.04496694e-02  3.44310179e-02\n",
      " -6.61241589e-03 -8.90119839e-03 -3.12849879e-02  3.10944691e-02\n",
      "  3.62673476e-02 -3.61334831e-02 -5.64406961e-02  1.52979707e-02\n",
      " -1.38744004e-02  4.84196544e-02 -3.97456810e-02 -1.64964348e-02\n",
      "  9.39748250e-03 -1.08891204e-02 -4.42709215e-02  5.07502966e-02\n",
      "  3.44792567e-02 -2.96341497e-02 -1.64302308e-02  4.15785797e-02\n",
      " -4.81570102e-02  4.83606458e-02  3.77876940e-03  5.08559542e-03\n",
      " -2.67351475e-02 -1.63014177e-02  7.32295215e-02  2.67139375e-02\n",
      "  5.64373210e-02 -5.11952266e-02  2.07509845e-02 -4.53410335e-02\n",
      "  4.08780500e-02  1.41661987e-02  1.15580996e-02 -1.61986388e-02\n",
      " -1.77985132e-02 -5.76748103e-02  4.05662842e-02 -4.30350080e-02\n",
      "  6.06826618e-02  2.56904159e-02  8.39414224e-02  1.89978839e-03\n",
      "  2.52233073e-02  1.55361583e-02  7.86273624e-04  2.76075932e-03\n",
      " -6.02087379e-02 -5.98988868e-02  8.37798864e-02 -2.09292844e-02\n",
      " -4.87794615e-02  7.82070041e-04  1.80677809e-02  5.89558203e-03\n",
      "  3.23672972e-35 -1.77099071e-02  4.39653099e-02  3.31627652e-02\n",
      "  2.92506982e-02 -5.70926182e-02  6.36313111e-03 -3.12086884e-02\n",
      "  1.50251528e-02 -2.29461864e-02  3.71415634e-03 -4.75074071e-03]\n",
      "Embedding size: (768,)\n"
     ]
    }
   ],
   "source": [
    "single_sentence = \"Who is Michael Jordan?\"\n",
    "single_embedding = embedding_model.encode(single_sentence)\n",
    "print(f\"Sentence: {single_sentence}\")\n",
    "print(f\"Embedding:\\n{single_embedding}\")\n",
    "print(f\"Embedding size: {single_embedding.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4491ef3",
   "metadata": {},
   "source": [
    "Nice! We've now got a way to numerically represent each of our chunks.\n",
    "\n",
    "Our embedding has a shape of `(768,)` meaning it's a vector of 768 numbers which represent our text in high-dimensional space, too many for a human to comprehend but machines love high-dimensional space.\n",
    "\n",
    "How about we add an embedding field to each of our chunk items?\n",
    "\n",
    "Let's start by trying to create embeddings on the CPU, we'll time it with the `%%time` magic to see how long it takes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ac3ac47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e645b356ec134795884bfb239d9f6b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1680 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11min 26s, sys: 11 s, total: 11min 37s\n",
      "Wall time: 11min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# the model is on the CPU\n",
    "embedding_model.to(\"cpu\")\n",
    "\n",
    "# Embed each chunk one by one\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f02aa2",
   "metadata": {},
   "source": [
    "This would take a *really* long time if we had a larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d63a324a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 397 μs, sys: 0 ns, total: 397 μs\n",
      "Wall time: 403 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'often. • Calm your “sweet tooth” by eating fruits, such as berries or an apple. • Replace sugary soft drinks with seltzer water, tea, or a small amount of 100 percent fruit juice added to water or soda water. The Food Industry: Functional Attributes of Carbohydrates and the Use of Sugar Substitutes In the food industry, both fast-releasing and slow-releasing carbohydrates are utilized to give foods a wide spectrum of functional attributes, including increased sweetness, viscosity, bulk, coating ability, solubility, consistency, texture, body, and browning capacity. The differences in chemical structure between the different carbohydrates confer their varied functional uses in foods. Starches, gums, and pectins are used as thickening agents in making jam, cakes, cookies, noodles, canned products, imitation cheeses, and a variety of other foods. Molecular gastronomists use slow- releasing carbohydrates, such as alginate, to give shape and texture to their fascinating food creations. Adding fiber to foods increases bulk. Simple sugars are used not only for adding sweetness, but also to add texture, consistency, and browning. In ice cream, the combination of sucrose and corn syrup imparts sweetness as well as a glossy appearance and smooth texture.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text_chunks=[item['sentence_chunk'] for item in pages_and_chunks_over_min_token_len]\n",
    "text_chunks[419]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd5e4524",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1680"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8b5364",
   "metadata": {},
   "source": [
    "### Save embeddings to file\n",
    "\n",
    "Since creating embeddings can be a timely process (not so much for our case but it can be for more larger datasets), let's turn our `pages_and_chunks_over_min_token_len` list of dictionaries into a DataFrame and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3340978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings to file\n",
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = \"text_chunks_and_embeddings_df.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05d2b9f",
   "metadata": {},
   "source": [
    "And we can make sure it imports nicely by loading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "447c4c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-39</td>\n",
       "      <td>Human Nutrition: 2020 Edition UNIVERSITY OF HA...</td>\n",
       "      <td>308</td>\n",
       "      <td>42</td>\n",
       "      <td>77.00</td>\n",
       "      <td>[ 6.74242601e-02  9.02280062e-02 -5.09550702e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-38</td>\n",
       "      <td>Human Nutrition: 2020 Edition by University of...</td>\n",
       "      <td>210</td>\n",
       "      <td>30</td>\n",
       "      <td>52.50</td>\n",
       "      <td>[ 5.52156679e-02  5.92137799e-02 -1.66167784e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-37</td>\n",
       "      <td>Contents Preface University of Hawai‘i at Māno...</td>\n",
       "      <td>766</td>\n",
       "      <td>116</td>\n",
       "      <td>191.50</td>\n",
       "      <td>[ 2.79801488e-02  3.39813270e-02 -2.06427258e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-36</td>\n",
       "      <td>Lifestyles and Nutrition University of Hawai‘i...</td>\n",
       "      <td>941</td>\n",
       "      <td>144</td>\n",
       "      <td>235.25</td>\n",
       "      <td>[ 6.82566613e-02  3.81274521e-02 -8.46859254e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-35</td>\n",
       "      <td>The Cardiovascular System University of Hawai‘...</td>\n",
       "      <td>998</td>\n",
       "      <td>152</td>\n",
       "      <td>249.50</td>\n",
       "      <td>[ 3.30264419e-02 -8.49772710e-03  9.57151968e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0          -39  Human Nutrition: 2020 Edition UNIVERSITY OF HA...   \n",
       "1          -38  Human Nutrition: 2020 Edition by University of...   \n",
       "2          -37  Contents Preface University of Hawai‘i at Māno...   \n",
       "3          -36  Lifestyles and Nutrition University of Hawai‘i...   \n",
       "4          -35  The Cardiovascular System University of Hawai‘...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0               308                42              77.00   \n",
       "1               210                30              52.50   \n",
       "2               766               116             191.50   \n",
       "3               941               144             235.25   \n",
       "4               998               152             249.50   \n",
       "\n",
       "                                           embedding  \n",
       "0  [ 6.74242601e-02  9.02280062e-02 -5.09550702e-...  \n",
       "1  [ 5.52156679e-02  5.92137799e-02 -1.66167784e-...  \n",
       "2  [ 2.79801488e-02  3.39813270e-02 -2.06427258e-...  \n",
       "3  [ 6.82566613e-02  3.81274521e-02 -8.46859254e-...  \n",
       "4  [ 3.30264419e-02 -8.49772710e-03  9.57151968e-...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import saved file and view\n",
    "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embedding_df_load.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a987dfe1",
   "metadata": {},
   "source": [
    "### Chunking and embedding questions\n",
    "\n",
    "Generally, the larger the vector size, the more information that gets encoded into the embedding (however, this is not always the case, as smaller, better models can outperform larger ones).\n",
    "\n",
    "Though with larger vector sizes comes larger storage and compute requirements.\n",
    "\n",
    "Our model is also relatively small (420MB) in size compared to larger models that are available.\n",
    "\n",
    "Larger models may result in better performance but will also require more compute.\n",
    "\n",
    "So some things to think about:\n",
    "* Size of input - If you need to embed longer sequences, choose a model with a larger input capacity.\n",
    "* Size of embedding vector - Larger is generally a better representation but requires more compute/storage.\n",
    "* Size of model - Larger models generally result in better embeddings but require more compute power/time to run.\n",
    "* Open or closed - Open models allow you to run them on your own hardware whereas closed models can be easier to setup but require an API call to get embeddings.\n",
    "\n",
    "If we've got a relatively small dataset, for example, under 100,000 examples (this number is rough and only based on first hand experience), `np.array` or `torch.tensor` can work just fine as your dataset.\n",
    "\n",
    "But if you've got a production system and want to work with 100,000+ embeddings, we may want to look into a [vector database]( https://en.wikipedia.org/wiki/Vector_database) (these have become very popular lately and there are many offerings).\n",
    "\n",
    "### Document Ingestion and Embedding Creation Extensions\n",
    "\n",
    "One major extension to the workflow above would to functionize it.\n",
    "\n",
    "Or turn it into a script.\n",
    "\n",
    "As in, take all the functionality we've created and package it into a single process (e.g. go from document -> embeddings file).\n",
    "\n",
    "So you could input a document on one end and have embeddings come out the other end. The hardest part of this is knowing what kind of preprocessing your text may need before it's turned into embeddings. Cleaner text generally means better results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc832d1",
   "metadata": {},
   "source": [
    "## 2. RAG - Search and Answer\n",
    "\n",
    "Let's say we had 1000s of customer support documents.\n",
    "\n",
    "You could use RAG to generate direct answers to questions with links to relevant documentation.\n",
    "\n",
    "Or you were an insurance company with large chains of claims emails.\n",
    "\n",
    "You could use RAG to answer questions about the emails with sources.\n",
    "\n",
    "One helpful analogy is to think of LLMs as calculators for words.\n",
    "\n",
    "With good inputs, the LLM can sort them into helpful outputs.\n",
    "\n",
    "How? \n",
    "\n",
    "It starts with better search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb1202e",
   "metadata": {},
   "source": [
    "### Similarity search\n",
    "\n",
    "Similarity search or semantic search or vector search is the idea of searching on *vibe*.\n",
    "\n",
    "If this sounds like woo, woo. It's not.\n",
    "\n",
    "Perhaps searching via *meaning* is a better analogy.\n",
    "\n",
    "With keyword search, you are trying to match the string \"apple\" with the string \"apple\".\n",
    "\n",
    "Whereas with similarity/semantic search, you may want to search \"macronutrients functions\".\n",
    "\n",
    "And get back results that don't necessarily contain the words \"macronutrients functions\" but get back pieces of text that match that meaning.\n",
    "\n",
    "Google kind of uses this workflow.\n",
    "\n",
    "But now we'd like to perform that across our own data.\n",
    "\n",
    "Let's import our embeddings we created earlier (tk -link to embedding file) and prepare them for use by turning them into a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0fd1795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1680, 768])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Import texts and embedding df\n",
    "text_chunks_and_embedding_df = pd.read_csv(\"text_chunks_and_embeddings_df.csv\")\n",
    "\n",
    "# Convert embedding column back to np.array (it got converted to string when it got saved to CSV)\n",
    "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
    "\n",
    "# Convert texts and embedding df to list of dicts\n",
    "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
    "\n",
    "# Convert embeddings to torch tensor and send to device (note: NumPy arrays are float64, torch tensors are float32 by default)\n",
    "embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c2b937b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-39</td>\n",
       "      <td>Human Nutrition: 2020 Edition UNIVERSITY OF HA...</td>\n",
       "      <td>308</td>\n",
       "      <td>42</td>\n",
       "      <td>77.00</td>\n",
       "      <td>[0.0674242601, 0.0902280062, -0.00509550702, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-38</td>\n",
       "      <td>Human Nutrition: 2020 Edition by University of...</td>\n",
       "      <td>210</td>\n",
       "      <td>30</td>\n",
       "      <td>52.50</td>\n",
       "      <td>[0.0552156679, 0.0592137799, -0.0166167784, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-37</td>\n",
       "      <td>Contents Preface University of Hawai‘i at Māno...</td>\n",
       "      <td>766</td>\n",
       "      <td>116</td>\n",
       "      <td>191.50</td>\n",
       "      <td>[0.0279801488, 0.033981327, -0.0206427258, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-36</td>\n",
       "      <td>Lifestyles and Nutrition University of Hawai‘i...</td>\n",
       "      <td>941</td>\n",
       "      <td>144</td>\n",
       "      <td>235.25</td>\n",
       "      <td>[0.0682566613, 0.0381274521, -0.00846859254, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-35</td>\n",
       "      <td>The Cardiovascular System University of Hawai‘...</td>\n",
       "      <td>998</td>\n",
       "      <td>152</td>\n",
       "      <td>249.50</td>\n",
       "      <td>[0.0330264419, -0.0084977271, 0.00957151968, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0          -39  Human Nutrition: 2020 Edition UNIVERSITY OF HA...   \n",
       "1          -38  Human Nutrition: 2020 Edition by University of...   \n",
       "2          -37  Contents Preface University of Hawai‘i at Māno...   \n",
       "3          -36  Lifestyles and Nutrition University of Hawai‘i...   \n",
       "4          -35  The Cardiovascular System University of Hawai‘...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0               308                42              77.00   \n",
       "1               210                30              52.50   \n",
       "2               766               116             191.50   \n",
       "3               941               144             235.25   \n",
       "4               998               152             249.50   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.0674242601, 0.0902280062, -0.00509550702, -...  \n",
       "1  [0.0552156679, 0.0592137799, -0.0166167784, -0...  \n",
       "2  [0.0279801488, 0.033981327, -0.0206427258, 0.0...  \n",
       "3  [0.0682566613, 0.0381274521, -0.00846859254, -...  \n",
       "4  [0.0330264419, -0.0084977271, 0.00957151968, -...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c9fc349f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.7424e-02,  9.0228e-02, -5.0955e-03, -3.1755e-02,  7.3908e-02,\n",
       "         3.5198e-02, -1.9799e-02,  4.6769e-02,  5.3573e-02,  5.0123e-03,\n",
       "         3.3393e-02, -1.6222e-03,  1.7608e-02,  3.6265e-02, -3.1676e-04,\n",
       "        -1.0712e-02,  1.5426e-02,  2.6218e-02,  2.7766e-03,  3.6494e-02,\n",
       "        -4.4411e-02,  1.8936e-02,  4.9012e-02,  1.6402e-02, -4.8578e-02,\n",
       "         3.1828e-03,  2.7299e-02, -2.0475e-03, -1.2283e-02, -7.2805e-02,\n",
       "         1.2045e-02,  1.0730e-02,  2.1000e-03, -8.1777e-02,  2.6783e-06,\n",
       "        -1.8143e-02, -1.2080e-02,  2.4717e-02, -6.2747e-02,  7.3544e-02,\n",
       "         2.2162e-02, -3.2877e-02, -1.8010e-02,  2.2295e-02,  5.6136e-02,\n",
       "         1.7951e-03,  5.2593e-02, -3.3174e-03, -8.3388e-03, -1.0629e-02,\n",
       "         2.3192e-03, -2.2393e-02, -1.5301e-02, -9.9306e-03,  4.6532e-02,\n",
       "         3.5747e-02, -2.5476e-02,  2.6370e-02,  3.7492e-03, -3.8268e-02,\n",
       "         2.5833e-02,  4.1287e-02,  2.5818e-02,  3.3297e-02, -2.5178e-02,\n",
       "         4.5152e-02,  4.4899e-04, -9.9662e-02,  4.9949e-02,  7.1351e-02,\n",
       "         6.9696e-02,  3.8524e-02,  9.9534e-03,  4.1864e-02, -3.2284e-02,\n",
       "        -4.3996e-03,  5.0505e-02, -5.5236e-02, -2.8011e-02, -2.2790e-02,\n",
       "        -1.7150e-02,  1.8790e-02,  1.5644e-02, -1.3989e-03, -6.5948e-03,\n",
       "         3.0239e-02,  6.3705e-03,  1.9674e-02, -4.1596e-03, -3.6431e-02,\n",
       "        -1.5817e-02,  2.3268e-02,  2.6860e-04,  2.1779e-02,  6.8912e-03,\n",
       "        -2.3242e-02,  7.2594e-02, -5.0120e-02,  8.0876e-02, -2.4889e-02,\n",
       "         2.9067e-02,  5.5249e-02, -9.3438e-02, -1.3212e-02,  1.5928e-03,\n",
       "         1.3798e-02,  2.1557e-02, -3.2791e-02, -2.9093e-02,  5.6236e-02,\n",
       "        -3.3690e-03,  8.6897e-03,  6.0683e-04, -1.2965e-02, -1.3540e-02,\n",
       "         1.2843e-02, -1.0498e-02, -4.5557e-02, -3.6739e-02, -7.1734e-02,\n",
       "         2.5452e-02,  5.3957e-02, -2.0675e-02,  4.8426e-02, -5.9083e-02,\n",
       "         1.0289e-01,  2.2616e-02,  1.0332e-02,  1.4436e-02, -4.9025e-02,\n",
       "        -9.4768e-03, -2.1910e-02, -2.8003e-02,  4.2353e-03, -1.5469e-03,\n",
       "         1.0504e-02, -6.6924e-03,  1.9085e-02,  1.4193e-02, -5.2069e-02,\n",
       "        -6.2259e-02, -2.9909e-02, -6.4276e-02, -2.3954e-02,  7.1420e-02,\n",
       "        -1.8304e-02,  8.0994e-02, -1.7956e-02,  3.7284e-02,  7.3538e-02,\n",
       "        -2.3727e-03, -4.5206e-02,  4.9306e-02,  6.3056e-02,  9.3635e-02,\n",
       "         8.6718e-03,  1.1217e-04, -3.4891e-02,  4.0274e-02,  5.2406e-02,\n",
       "         8.5511e-03, -1.1130e-04, -8.9698e-02, -1.5250e-02, -7.3226e-03,\n",
       "         3.4598e-02,  1.0275e-02, -1.7100e-02,  1.4606e-02,  4.2193e-02,\n",
       "        -5.6059e-02,  3.1530e-03, -1.9318e-02, -1.3782e-02,  5.0487e-02,\n",
       "         3.0552e-02, -4.7781e-02,  6.2093e-03,  4.1689e-02, -1.7510e-02,\n",
       "         4.4075e-02, -7.4118e-02,  1.7875e-02,  2.8083e-04, -5.2933e-02,\n",
       "        -8.4026e-03, -3.7716e-03, -1.9980e-02,  4.4250e-02, -4.0436e-02,\n",
       "         3.7072e-02,  2.2813e-04, -2.6127e-02, -8.1365e-02,  7.3485e-05,\n",
       "         3.3910e-03,  8.9397e-03, -1.7945e-02,  2.7148e-02, -7.7686e-02,\n",
       "         5.1004e-02,  2.9654e-02,  2.6449e-02, -7.9366e-04, -3.2182e-02,\n",
       "         3.8037e-02,  2.3772e-02, -1.3111e-02,  2.0045e-02, -2.0727e-03,\n",
       "        -5.8578e-02, -1.5149e-02,  4.7396e-02,  9.3716e-03, -2.2722e-02,\n",
       "        -3.4904e-03, -1.1110e-02, -1.7302e-02,  1.9112e-02,  7.3328e-02,\n",
       "         2.5272e-02,  2.2991e-02, -8.6338e-02, -2.0524e-02, -2.4073e-02,\n",
       "         7.8516e-03,  5.9223e-02, -1.9505e-02,  7.2794e-04,  4.8634e-02,\n",
       "         3.9010e-02,  5.4596e-02, -3.7900e-02,  2.1420e-02,  2.4441e-03,\n",
       "         4.1473e-02,  7.6787e-02,  3.9155e-02, -2.1141e-02,  4.8422e-02,\n",
       "        -5.9322e-02,  2.9802e-03, -3.8935e-02, -3.5006e-03, -6.1465e-02,\n",
       "         2.8272e-02, -3.5795e-02, -2.4533e-02, -6.7368e-02,  9.3984e-02,\n",
       "         2.5381e-02, -8.7609e-03,  9.6247e-03,  1.6570e-02, -5.3413e-02,\n",
       "        -1.8370e-02, -5.4454e-02, -5.1886e-02, -3.9982e-02,  6.0174e-02,\n",
       "        -4.0211e-02,  3.4026e-02,  7.1233e-03, -1.7635e-02,  2.6353e-02,\n",
       "        -8.1668e-02,  4.1597e-02,  1.1054e-02,  7.7329e-03, -3.5506e-02,\n",
       "        -5.8768e-03, -1.4153e-02, -2.7146e-02,  2.3820e-02, -3.4479e-03,\n",
       "         3.2835e-02,  4.4337e-03, -3.0013e-02,  4.7975e-02, -4.0580e-02,\n",
       "        -2.1400e-02,  7.8742e-02, -1.5630e-02,  1.8930e-02,  2.6756e-02,\n",
       "        -4.1777e-02,  6.4978e-03,  1.6041e-03,  6.6808e-02, -5.2895e-02,\n",
       "         4.1844e-02, -5.3879e-02,  2.9447e-02,  1.4860e-02, -4.2965e-02,\n",
       "         3.4447e-02, -2.7505e-02,  1.3751e-02,  4.0990e-02, -8.8895e-03,\n",
       "        -3.0511e-03,  3.3440e-02, -4.0466e-03,  3.2865e-02, -1.4609e-02,\n",
       "         2.0716e-02, -3.0506e-03, -3.8943e-02,  4.8812e-03, -2.9872e-02,\n",
       "         1.7439e-03,  8.6081e-02,  6.6861e-03, -1.6257e-02, -8.1287e-03,\n",
       "        -3.5705e-02, -4.7969e-02,  2.2529e-02,  2.2744e-02, -1.9378e-03,\n",
       "         1.1901e-02, -1.0321e-02, -1.3257e-02, -1.4464e-02, -3.1800e-03,\n",
       "        -2.8914e-02,  4.8882e-03,  4.5425e-02, -1.0888e-01, -4.4595e-02,\n",
       "        -1.6905e-03,  1.7857e-02,  5.7418e-02, -1.3633e-02,  2.3022e-02,\n",
       "        -4.6197e-02, -3.1276e-02,  6.2126e-03, -4.9911e-02, -3.6829e-02,\n",
       "        -3.4771e-02,  2.0125e-03,  3.9957e-04,  6.6996e-02, -1.7236e-02,\n",
       "        -5.3030e-02,  9.9722e-03,  2.3808e-02, -1.7870e-02,  1.9527e-02,\n",
       "        -5.1236e-02, -3.7996e-02,  2.5240e-02, -3.1528e-02,  2.8217e-02,\n",
       "        -1.4053e-02,  2.7565e-02, -7.5723e-03, -3.1351e-02, -1.0788e-03,\n",
       "         3.0862e-02,  8.4648e-02, -2.3276e-02, -6.3262e-02,  6.4850e-02,\n",
       "         5.1187e-02, -4.6952e-03,  2.1690e-02,  2.2844e-02, -1.7596e-02,\n",
       "        -1.8004e-06,  5.0318e-02, -1.4955e-02,  1.5985e-02,  2.3258e-03,\n",
       "        -5.8727e-02,  3.7002e-02,  7.2775e-02, -3.3827e-02, -1.8754e-02,\n",
       "         4.6750e-02, -1.5560e-02,  3.5652e-02,  9.9983e-03, -2.0313e-02,\n",
       "        -5.6848e-02, -4.9714e-02, -2.9255e-02,  2.4087e-02, -4.6807e-02,\n",
       "         1.0582e-02,  4.2213e-03, -8.8040e-03, -2.4846e-03,  7.1091e-03,\n",
       "        -4.0459e-03,  1.7800e-02, -2.3911e-02, -6.8737e-03,  3.7128e-02,\n",
       "        -1.4069e-02, -1.2391e-02,  3.3488e-02,  3.9902e-02, -1.6672e-02,\n",
       "         1.4881e-02,  3.4921e-02,  4.1948e-02,  4.1065e-02,  2.8329e-02,\n",
       "         3.0433e-02, -2.0902e-02,  2.8019e-02, -5.1244e-02,  2.0353e-02,\n",
       "        -1.4630e-02, -9.9522e-03, -2.1091e-02,  4.4857e-02, -3.2936e-02,\n",
       "        -4.5591e-02,  4.4177e-02, -2.7671e-03,  5.7345e-02, -4.1760e-03,\n",
       "        -2.9215e-02,  2.7704e-02, -1.5260e-02, -6.1995e-02,  2.9332e-02,\n",
       "         4.4823e-02,  2.1181e-02, -9.1190e-03, -3.6573e-03, -3.8881e-02,\n",
       "         1.7185e-02,  7.2466e-02, -5.5369e-02, -4.0100e-02, -1.9544e-02,\n",
       "        -1.3069e-02,  1.2657e-02,  4.2051e-03, -3.1517e-02,  9.3332e-03,\n",
       "         7.5866e-03,  1.2584e-02,  3.9474e-02,  9.2081e-02,  3.6145e-02,\n",
       "         2.1324e-02,  9.9829e-03, -2.4977e-02,  4.9934e-02,  3.2386e-02,\n",
       "        -8.3486e-04,  4.2720e-02, -5.2461e-02,  1.9335e-02, -2.2124e-02,\n",
       "         4.5479e-02, -1.2786e-02, -1.7430e-02,  2.5903e-02, -2.3038e-02,\n",
       "        -3.1163e-02,  1.5773e-02,  2.0823e-03, -3.2866e-02, -2.6236e-02,\n",
       "        -4.7034e-02,  5.6060e-02,  5.2010e-03,  1.2913e-02,  1.7967e-02,\n",
       "        -1.7415e-02, -5.5965e-02, -1.7394e-02, -2.7446e-02,  3.9135e-02,\n",
       "        -4.8180e-03,  2.6728e-03, -8.5086e-03, -4.7705e-02,  5.8734e-03,\n",
       "         7.4839e-03, -3.3042e-02, -2.7491e-02, -8.2584e-03, -4.7996e-02,\n",
       "         1.5387e-02,  4.0562e-02, -1.7994e-02, -1.5388e-02, -5.4152e-03,\n",
       "         3.6740e-02, -3.1735e-02, -9.0053e-03, -1.2232e-02,  2.1254e-02,\n",
       "         1.1946e-02, -8.7441e-03,  1.6887e-02, -1.4598e-02, -3.3291e-02,\n",
       "         3.6413e-02, -5.1191e-02,  7.4621e-03, -3.6541e-02, -4.2688e-02,\n",
       "        -2.8181e-02, -1.3403e-02,  2.6602e-02,  2.1015e-02, -1.6868e-02,\n",
       "        -6.1321e-02, -2.1096e-03, -2.4802e-02,  2.2264e-02,  9.2585e-03,\n",
       "        -5.5378e-03, -5.5574e-02,  7.0564e-03, -2.4968e-02, -2.0095e-02,\n",
       "         6.4292e-03,  1.3989e-02, -1.4590e-02, -4.8052e-02,  8.3201e-02,\n",
       "         5.4959e-02,  2.7590e-02, -4.8724e-03,  4.7631e-02,  2.1821e-02,\n",
       "        -7.3083e-03, -2.9660e-02,  3.7069e-03, -6.4659e-02, -2.8210e-02,\n",
       "         7.4636e-03, -8.5547e-02,  1.2753e-02,  2.8452e-03,  1.8569e-02,\n",
       "         5.4310e-02, -1.2299e-01, -7.5443e-02,  2.1505e-02, -1.2050e-01,\n",
       "         3.2535e-03, -6.5991e-04,  1.9949e-03, -9.9721e-03,  5.7540e-02,\n",
       "        -6.9637e-33,  3.8571e-02, -4.3609e-02,  2.1520e-02,  1.8536e-02,\n",
       "         4.1757e-02,  2.0367e-02, -1.1547e-02, -2.7678e-02, -1.8432e-02,\n",
       "         8.4662e-03, -8.7625e-04,  8.2841e-04,  2.2791e-02, -3.1303e-02,\n",
       "         2.5084e-02, -8.7316e-03, -4.6752e-03, -2.5510e-02,  5.0539e-03,\n",
       "        -3.3755e-02, -4.9492e-02,  1.5632e-02, -6.8096e-03,  2.4801e-02,\n",
       "         3.0501e-02,  2.1558e-02,  2.2217e-02, -1.8151e-02, -5.8037e-02,\n",
       "        -1.7057e-02,  1.6337e-02,  2.1900e-02,  2.7349e-02,  3.9039e-02,\n",
       "        -2.3340e-02, -6.2867e-02,  2.0381e-02, -3.0317e-02, -3.2317e-02,\n",
       "        -7.2066e-02, -3.8694e-02, -9.8273e-03,  2.5109e-02,  3.6795e-02,\n",
       "        -1.7297e-02,  3.0267e-02, -1.5756e-02, -3.9794e-02,  2.3033e-02,\n",
       "         3.1124e-02, -1.9287e-02,  1.1844e-02, -4.8267e-03,  4.0781e-02,\n",
       "         1.0386e-03,  1.0464e-01,  1.9063e-02,  8.3570e-03,  2.5337e-03,\n",
       "        -3.1320e-03, -2.7825e-02,  1.8403e-02,  2.0702e-02,  3.6908e-02,\n",
       "         2.7416e-03, -6.0158e-02,  2.9791e-02,  1.8967e-02, -3.4473e-02,\n",
       "         1.5104e-02, -3.6422e-02, -2.4567e-02,  1.1861e-02,  1.5127e-02,\n",
       "        -2.7633e-02, -8.7480e-02, -1.2038e-02,  8.1492e-02,  1.3494e-04,\n",
       "        -7.9990e-03, -8.2924e-02, -1.4916e-03,  2.3558e-02,  7.7107e-03,\n",
       "        -4.4561e-02,  5.7388e-03, -1.6240e-02,  7.5965e-03,  2.8973e-03,\n",
       "         3.0138e-03, -1.8075e-02, -1.6125e-02,  7.4536e-03,  3.0270e-02,\n",
       "         5.3882e-02, -8.8307e-03,  4.1331e-02, -4.5255e-02,  2.6336e-02,\n",
       "        -2.3341e-02, -5.7294e-02,  3.0712e-02,  3.2013e-02, -2.2280e-02,\n",
       "         2.1893e-02, -8.8448e-02, -1.6441e-02, -1.8578e-02,  3.1832e-02,\n",
       "        -5.1782e-02,  1.1617e-02, -4.0834e-03,  4.0055e-02, -2.3541e-02,\n",
       "        -4.2422e-02,  1.2550e-02,  4.6806e-02,  3.4818e-02,  5.2723e-02,\n",
       "         1.2301e-02, -4.1894e-02, -6.2661e-03,  1.3237e-02, -7.7754e-02,\n",
       "        -4.5433e-03, -4.8801e-02,  1.6945e-02,  2.7172e-02, -1.5703e-02,\n",
       "        -1.9612e-02,  5.4214e-02, -1.0483e-02,  3.1630e-07,  1.2421e-02,\n",
       "        -2.5716e-02, -1.3393e-02, -1.1920e-01, -1.7808e-02, -3.8919e-02,\n",
       "         5.4256e-02,  3.0124e-03, -1.1077e-02,  7.0452e-03,  6.0348e-02,\n",
       "        -5.5597e-02,  2.3159e-03, -1.3970e-02,  4.7007e-02,  1.1927e-02,\n",
       "        -1.9804e-02, -2.2539e-02, -1.1684e-02, -4.7200e-03,  8.4689e-03,\n",
       "         3.2068e-02, -2.6291e-02, -5.7842e-02,  2.1788e-02,  1.2782e-02,\n",
       "        -1.2676e-02, -5.4928e-02, -1.7036e-02, -3.7918e-02, -2.4087e-02,\n",
       "         1.8712e-02,  5.3388e-02, -4.9064e-02, -6.8377e-02, -4.9259e-02,\n",
       "        -1.8381e-02, -4.3865e-03, -6.1605e-02,  9.1380e-03, -5.5073e-02,\n",
       "         5.1462e-02, -3.0244e-02, -3.7612e-02, -1.2178e-02, -2.2920e-02,\n",
       "        -5.9107e-03,  5.5501e-02,  3.2965e-02, -2.2425e-02,  6.9092e-03,\n",
       "         5.7824e-03,  1.3703e-02,  3.6597e-02, -1.7868e-02,  4.0320e-02,\n",
       "         3.9890e-02,  2.2399e-02,  3.5767e-02, -4.6013e-02, -2.4015e-02,\n",
       "         6.7122e-03, -5.1820e-02, -4.2709e-02, -5.3403e-02,  7.7334e-03,\n",
       "         2.8628e-02,  3.2577e-34, -5.5594e-02, -1.8639e-02, -1.0194e-03,\n",
       "        -3.2433e-02,  1.4610e-02,  9.1389e-03, -2.7832e-02,  1.9247e-02,\n",
       "        -2.2115e-02, -2.3214e-02,  1.2569e-02])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb018c2",
   "metadata": {},
   "source": [
    "Nice!\n",
    "\n",
    "Now let's prepare another instance of our embedding model. Not because we have to but because we'd like to make it so you can start the notebook from the cell above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54eb53a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import util, SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=device) # choose the device to load the model to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a9e582",
   "metadata": {},
   "source": [
    "Embedding model ready!\n",
    "\n",
    "Time to perform a semantic search.\n",
    "\n",
    "Let's say you were studying the macronutrients.\n",
    "\n",
    "And wanted to search your textbook for \"macronutrients functions\".\n",
    "\n",
    "Well, we can do so with the following steps:\n",
    "1. Define a query string (e.g. `\"macronutrients functions\"`) - note: this could be anything, specific or not.\n",
    "2. Turn the query string in an embedding with same model we used to embed our text chunks.\n",
    "3. Perform a [dot product](https://pytorch.org/docs/stable/generated/torch.dot.html) or [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity) function between the text embeddings and the query embedding (we'll get to what these are shortly) to get similarity scores.\n",
    "4. Sort the results from step 3 in descending order (a higher score means more similarity in the eyes of the model) and use these values to inspect the texts. \n",
    "\n",
    "Easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e57ed6a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: macronutrients function\n",
      "Time take to get scores on 1680 embeddings: 0.00052 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.7085, 0.6669, 0.6496, 0.6391, 0.6130]),\n",
       "indices=tensor([42, 47, 41, 46, 51]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Define the query\n",
    "query=\"macronutrients function\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# 2. Embed the query to the same numerical space as the text examples \n",
    "# Note: It's important to embed your query with the same model you embedded your examples with.\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "# 3. Get similarity scores with the dot product (we'll time this for fun)\n",
    "from time import perf_counter as timer\n",
    "\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"Time take to get scores on {len(embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")\n",
    "\n",
    "# 4. Get the top-k results (we'll keep this to 5)\n",
    "top_results_dot_product = torch.topk(dot_scores, k=5)\n",
    "top_results_dot_product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9690e621",
   "metadata": {},
   "source": [
    "Woah!! Now that was fast!\n",
    "\n",
    "~0.00038 seconds to perform a dot product comparison across 1680 embeddings on my machine.\n",
    "\n",
    "GPUs are optimized for these kinds of operations.\n",
    "\n",
    "So even if you we're to increase our embeddings by 100x (1680 -> 168,000), an exhaustive dot product operation would happen in ~0.038 seconds (assuming linear scaling).\n",
    "\n",
    "Heck, let's try it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "25951df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_number': 5,\n",
       " 'sentence_chunk': 'Macronutrients Nutrients that are needed in large amounts are called macronutrients. There are three classes of macronutrients: carbohydrates, lipids, and proteins. These can be metabolically processed into cellular energy. The energy from macronutrients comes from their chemical bonds. This chemical energy is converted into cellular energy that is then utilized to perform work, allowing our bodies to conduct their basic functions. A unit of measurement of food energy is the calorie. On nutrition food labels the amount given for “calories” is actually equivalent to each calorie multiplied by one thousand. A kilocalorie (one thousand calories, denoted with a small “c”) is synonymous with the “Calorie” (with a capital “C”) on nutrition food labels. Water is also a macronutrient in the sense that you require a large amount of it, but unlike the other macronutrients, it does not yield calories. Carbohydrates Carbohydrates are molecules composed of carbon, hydrogen, and oxygen.',\n",
       " 'chunk_char_count': 987,\n",
       " 'chunk_word_count': 149,\n",
       " 'chunk_token_count': 246.75,\n",
       " 'embedding': array([ 5.12206256e-02, -4.26197723e-02,  1.97356008e-02,  1.30613567e-02,\n",
       "         5.76598160e-02,  1.50817540e-02, -8.98824334e-02,  3.10131237e-02,\n",
       "        -2.98853312e-02, -3.47163118e-02,  3.21012549e-02,  1.07060922e-02,\n",
       "         2.06893310e-02,  3.23250704e-02,  3.62949185e-02, -3.53822149e-02,\n",
       "         6.14872053e-02, -4.20648381e-02, -3.95431444e-02,  3.16183567e-02,\n",
       "         5.24913310e-04,  5.43846563e-03,  3.73274870e-02, -9.44858976e-03,\n",
       "        -1.07091673e-01,  5.05331010e-02,  2.96340566e-02,  1.15390858e-02,\n",
       "        -2.46292516e-03, -5.12201972e-02, -8.93942360e-03, -1.50753697e-03,\n",
       "        -4.07981016e-02, -3.03627625e-02,  2.09010636e-06, -4.28525172e-02,\n",
       "        -3.43207233e-02,  6.94913790e-03, -7.17835352e-02,  1.22951809e-02,\n",
       "        -4.46255365e-03, -5.22793829e-02,  2.00276412e-02, -1.34436330e-02,\n",
       "         4.98107225e-02,  3.58145013e-02,  4.80721779e-02, -3.26666385e-02,\n",
       "        -3.76312025e-02, -7.63258571e-03,  6.88405288e-03, -5.60146244e-03,\n",
       "         2.25824267e-02, -1.74588021e-02,  3.06603145e-02,  4.68476564e-02,\n",
       "         1.86912026e-02,  7.59701058e-02, -1.06622251e-02,  4.57864664e-02,\n",
       "         2.90247183e-02,  1.99847519e-02,  9.43731517e-03, -1.29955634e-02,\n",
       "         5.31571396e-02,  6.15916476e-02, -5.04084341e-02, -2.54437104e-02,\n",
       "        -3.56726436e-04,  5.59727736e-02, -2.37430483e-02,  1.07695535e-02,\n",
       "         2.26447918e-02,  2.21036188e-03, -1.82256307e-02, -1.35282371e-02,\n",
       "         4.39407676e-02, -2.17776708e-02,  4.27759178e-02,  1.18115740e-02,\n",
       "        -8.25893786e-03,  1.60724241e-02,  2.82430220e-02, -1.11974925e-02,\n",
       "        -2.45931372e-02, -6.06058091e-02, -3.71069349e-02, -4.58621932e-03,\n",
       "        -1.80645951e-03, -3.78605463e-02, -9.56856906e-02, -3.32345180e-02,\n",
       "         5.13073206e-02,  1.19459052e-02,  8.91532004e-02, -2.07037665e-02,\n",
       "        -1.70694944e-02,  6.89378083e-02,  7.98153132e-02, -5.33365607e-02,\n",
       "        -3.27836648e-02, -2.75643375e-02,  1.19160386e-02,  1.96792390e-02,\n",
       "         2.09319452e-03,  8.88268743e-03, -7.58035108e-03, -5.34666553e-02,\n",
       "        -4.95695211e-02,  8.67316406e-03, -4.69777659e-02, -2.12228298e-02,\n",
       "        -4.15335894e-02,  3.72832455e-02, -3.81441154e-02,  4.74060290e-02,\n",
       "        -3.88260372e-02, -7.18369382e-03, -3.15469988e-02,  1.76315494e-02,\n",
       "        -1.44514050e-02,  3.07651255e-02,  3.46488357e-02, -8.39261338e-03,\n",
       "        -3.14043947e-02,  5.50121404e-02,  1.90810282e-02, -6.29032627e-02,\n",
       "         9.10235383e-03, -6.42892122e-02,  1.39967082e-02, -7.07596075e-03,\n",
       "        -2.94536892e-02,  2.08528917e-02, -1.04387188e-02,  1.02603184e-02,\n",
       "         4.33670990e-02, -1.68561395e-02,  2.88609806e-02, -8.11358690e-02,\n",
       "        -1.04753979e-01, -4.55289744e-02, -5.13247922e-02,  1.25923241e-02,\n",
       "         8.64885375e-03,  4.51926561e-03,  4.56908084e-02,  4.67329435e-02,\n",
       "         5.80705479e-02, -1.13196042e-03,  4.56143450e-03,  4.15874682e-02,\n",
       "         4.27243896e-02,  2.82419426e-03,  4.70684282e-02, -2.30714455e-02,\n",
       "         2.05918215e-02, -4.54461351e-02,  6.81779236e-02,  1.11990245e-02,\n",
       "         5.20031434e-03, -1.66078322e-02, -2.03240439e-02, -1.76641215e-02,\n",
       "        -2.53125355e-02, -4.15261798e-02,  1.21012582e-02, -7.14607770e-03,\n",
       "         1.50870942e-02,  1.43980775e-02, -1.42068295e-02, -1.47211617e-02,\n",
       "        -1.84840504e-02,  3.73983458e-02,  4.82297465e-02,  8.26246664e-03,\n",
       "         8.70432530e-04,  1.63980741e-02, -4.14804928e-02,  1.76652241e-02,\n",
       "         2.92759202e-02, -2.03148592e-02,  6.03397237e-03,  3.39284576e-02,\n",
       "        -5.11279628e-02, -3.29859331e-02,  1.19596664e-02, -5.89680821e-02,\n",
       "         1.49900485e-02, -2.48976834e-02,  5.55844866e-02, -1.96321830e-02,\n",
       "         7.50950221e-06, -6.87670484e-02,  3.23560461e-02, -1.10599371e-02,\n",
       "        -1.78017616e-02,  8.66483897e-03, -6.42556790e-03, -2.59781629e-02,\n",
       "         2.72192471e-02,  8.66381600e-02, -2.93232836e-02,  1.56847704e-02,\n",
       "        -8.42268020e-02,  2.29734983e-02,  3.90508026e-02,  1.46789644e-02,\n",
       "        -1.37603935e-03, -1.14772897e-02, -4.87182336e-03, -4.14112918e-02,\n",
       "        -3.32237512e-04, -1.28843179e-02, -3.15791927e-03, -6.54503182e-02,\n",
       "        -1.16173513e-02, -2.91303545e-02, -5.44329509e-02,  2.17898916e-02,\n",
       "         2.12140903e-02, -2.21223943e-02, -7.13877305e-02, -5.07890768e-02,\n",
       "         8.56906623e-02, -4.96718585e-02, -1.72054186e-03, -1.25248963e-02,\n",
       "        -8.32402036e-02,  1.83944684e-02,  4.81732823e-02,  5.68843037e-02,\n",
       "        -2.20833477e-02, -6.83016004e-03, -3.79386730e-02, -3.55391540e-02,\n",
       "        -1.74433812e-02,  4.68359403e-02, -8.91757663e-03,  4.86650765e-02,\n",
       "        -2.11816914e-02, -3.28907669e-02,  2.44305134e-02,  1.11137442e-02,\n",
       "        -5.00013493e-02,  2.15978622e-02, -4.26010303e-02, -1.19191445e-02,\n",
       "        -6.02720538e-03,  5.59981875e-02,  2.28939708e-02,  9.75416601e-03,\n",
       "         1.61254704e-02, -8.22238065e-03,  2.17042100e-02, -9.24524385e-03,\n",
       "         6.48605525e-02, -2.86091343e-02,  8.20322055e-03,  2.80465446e-02,\n",
       "         7.18477517e-02,  1.23419904e-03,  3.20823342e-02,  1.71127580e-02,\n",
       "        -5.36557212e-02, -2.59170868e-02, -7.83943292e-03,  4.85569499e-02,\n",
       "         7.65658030e-03, -1.14301564e-02,  1.63091291e-02,  2.42607519e-02,\n",
       "        -9.45916865e-04,  5.39970696e-02,  8.63446388e-03,  1.68762729e-02,\n",
       "         3.64885777e-02, -3.27896141e-02,  1.31791998e-02, -1.29420962e-02,\n",
       "        -1.47349285e-02,  4.01211120e-02,  2.64455434e-02,  2.14625336e-02,\n",
       "        -7.74359470e-03,  2.46680714e-02,  3.14296619e-03,  1.34802964e-02,\n",
       "         7.77451396e-02, -1.39843533e-02,  5.59257194e-02, -1.61790680e-02,\n",
       "        -2.97737727e-03, -8.85165576e-03, -9.58820805e-03,  5.59056923e-03,\n",
       "         3.50932777e-02, -3.85740101e-02,  3.82848755e-02,  2.14204304e-02,\n",
       "         4.16783849e-03, -2.03425083e-02, -6.76702186e-02,  1.88577082e-02,\n",
       "        -9.57168173e-03,  2.79921349e-02,  1.37692709e-02, -1.86339375e-02,\n",
       "         6.89146072e-02,  5.22053204e-02,  1.06270313e-02,  5.14396094e-02,\n",
       "        -1.23038590e-02,  4.24455665e-02, -6.09480813e-02,  1.26481894e-02,\n",
       "        -2.98744999e-02,  6.77426830e-02,  3.19172479e-02, -3.52336317e-02,\n",
       "         6.28783647e-03, -3.27923661e-03, -1.90394819e-02, -1.96799114e-02,\n",
       "        -2.24826857e-02,  7.21124187e-03, -3.31810005e-02,  8.80562663e-02,\n",
       "        -8.00812095e-02,  2.34367102e-02, -3.13476920e-02,  2.47505195e-02,\n",
       "         2.94469837e-02,  2.42623370e-02,  2.54903864e-02,  1.86421536e-02,\n",
       "        -3.26942988e-02, -3.21797021e-02,  4.35435213e-03, -2.12304667e-02,\n",
       "        -3.35889459e-02, -1.24098100e-02, -1.59351330e-03,  7.88185298e-02,\n",
       "         3.76581736e-02,  7.27089122e-02,  4.05481197e-02, -6.92263991e-03,\n",
       "         1.61999017e-02,  3.81626152e-02, -3.29871825e-03,  3.39786964e-03,\n",
       "        -7.60584511e-03, -1.41148246e-03, -1.33250458e-02,  7.66779333e-02,\n",
       "        -8.62755254e-03, -1.59633029e-02, -2.91218422e-02, -6.19481467e-02,\n",
       "         6.51340932e-02,  7.80710056e-02, -6.48326203e-02, -5.71082458e-02,\n",
       "         3.09011079e-02, -6.17981888e-03, -1.55527908e-02,  2.85683270e-03,\n",
       "         1.67835373e-02, -1.39425024e-02,  2.73235217e-02, -2.15966087e-02,\n",
       "        -3.98228469e-04, -5.62370173e-04,  1.28166499e-02,  1.22626149e-03,\n",
       "         2.82254592e-02,  3.95408422e-02, -1.18189447e-01,  1.74514968e-02,\n",
       "         1.49927167e-02,  1.87664442e-02,  3.58752050e-02, -9.38477181e-03,\n",
       "        -7.47183757e-03,  1.03581455e-02, -2.89553925e-02, -2.83715017e-02,\n",
       "         6.40503764e-02, -5.47635518e-02,  1.34002343e-02, -4.44100574e-02,\n",
       "        -7.21827745e-02,  4.05690186e-02, -9.43316729e-04,  1.44825047e-02,\n",
       "        -2.99104825e-02,  1.07989302e-02, -1.99926067e-02,  2.60403976e-02,\n",
       "         3.68308015e-02, -1.84924509e-02,  6.57837689e-02, -9.11417790e-03,\n",
       "         6.66800304e-04,  4.29192595e-02,  5.39137311e-02, -6.67373138e-03,\n",
       "        -5.47644822e-03,  3.56545709e-02,  9.74677876e-03, -6.72662184e-02,\n",
       "        -2.91336402e-02, -1.33687677e-02,  1.52671114e-02,  2.32470203e-02,\n",
       "         1.22048974e-03,  5.07128378e-03,  3.50581892e-02, -1.10612828e-02,\n",
       "        -4.96193059e-02, -1.03339683e-02,  1.58703458e-02,  5.57396887e-03,\n",
       "        -8.41477290e-02,  1.46636730e-02, -1.90380719e-02,  2.06015017e-02,\n",
       "        -2.46869959e-02,  3.85333747e-02,  2.09518382e-03, -7.00801387e-02,\n",
       "        -1.37359612e-02, -1.01724453e-02, -5.90134561e-02,  6.45321757e-02,\n",
       "         5.85188456e-02, -7.51207620e-02,  3.02050752e-03,  1.02363415e-02,\n",
       "        -5.27154002e-03,  2.75019649e-02,  3.74608347e-03, -6.33774232e-03,\n",
       "         1.15085696e-03,  5.50109148e-02, -2.21076868e-02, -3.91179882e-02,\n",
       "         7.24823177e-02,  1.98626742e-02,  1.82016455e-02,  3.04597039e-02,\n",
       "        -6.48682639e-02,  8.08702409e-02,  2.45367642e-02,  1.11444853e-02,\n",
       "        -4.76422571e-02,  4.56587970e-03, -2.81585706e-03, -7.88682103e-02,\n",
       "         1.68548673e-02, -1.72774196e-02, -2.18883269e-02,  6.90075918e-04,\n",
       "        -6.29118383e-02, -3.79278557e-03,  5.01790680e-02, -6.64927959e-02,\n",
       "        -1.44832181e-02, -2.13097483e-02, -1.90430542e-03,  2.36837938e-02,\n",
       "        -7.37537304e-03, -1.13887703e-02,  4.16967832e-02, -7.12385550e-02,\n",
       "         1.64448144e-03, -2.71906834e-02, -1.00597609e-02,  5.68652116e-02,\n",
       "        -1.59575902e-02, -2.18626801e-02,  2.95809861e-02,  1.32436333e-02,\n",
       "         6.84043020e-03, -2.32375041e-02,  2.30216775e-02, -2.83628609e-02,\n",
       "        -7.53523456e-03, -6.13192953e-02,  2.78964862e-02,  7.69140646e-02,\n",
       "        -2.20717378e-02, -5.54075167e-02,  4.10174578e-03, -1.86913367e-02,\n",
       "         1.98104791e-02, -8.79301410e-03,  3.64848673e-02,  3.39769050e-02,\n",
       "         5.12780659e-02, -2.33525205e-02,  9.18409042e-03, -2.00319663e-02,\n",
       "        -1.99404149e-03,  2.12422647e-02, -1.97834093e-02, -2.45846882e-02,\n",
       "         1.06189605e-02,  8.33639875e-03, -2.37421039e-02,  3.34301591e-02,\n",
       "         9.77974851e-03,  7.12097436e-02, -2.83091329e-02, -8.49852934e-02,\n",
       "        -1.90318394e-02,  8.11631326e-03, -1.77514274e-02, -2.63862107e-02,\n",
       "         2.13689096e-02, -4.03648801e-02, -5.73522039e-03, -1.78485569e-02,\n",
       "         1.95428487e-02,  4.72576693e-02,  1.18539585e-02,  1.90282881e-03,\n",
       "        -4.95081283e-02,  4.68240753e-02,  3.50180604e-02, -1.06982896e-02,\n",
       "        -2.17255205e-02, -4.43654656e-02,  1.96755845e-02,  6.33003861e-02,\n",
       "        -1.04450196e-01,  4.90761129e-03, -3.49746719e-02,  1.82479843e-02,\n",
       "        -4.48661717e-03, -1.80579256e-02,  1.75676830e-02,  2.44325548e-02,\n",
       "         4.84508984e-02,  2.89442968e-02, -3.35029997e-02, -5.95786944e-02,\n",
       "         6.59437338e-03, -8.16655606e-02, -7.21411873e-03,  6.02774285e-02,\n",
       "        -1.12553481e-02, -2.55421940e-02,  8.09146613e-02, -5.94383282e-33,\n",
       "         3.02098375e-02, -8.92082006e-02,  6.49119914e-03,  9.60945860e-02,\n",
       "        -1.93734933e-02,  6.53395206e-02, -1.14361215e-02, -1.10448683e-02,\n",
       "        -2.04059817e-02,  1.09527176e-02,  3.00813988e-02,  1.57746691e-02,\n",
       "         1.61110591e-02, -2.45360192e-02,  3.83537970e-02, -2.73477416e-02,\n",
       "         3.25411409e-02, -3.87462154e-02, -9.24405921e-03, -5.23299037e-04,\n",
       "        -2.05825865e-02, -4.33794037e-02,  3.30365412e-02, -3.97203676e-03,\n",
       "         5.11728227e-02, -1.30961684e-03,  1.67805683e-02,  9.70007572e-03,\n",
       "        -1.71038241e-03,  3.79025713e-02, -6.72443677e-03,  7.52368718e-02,\n",
       "         3.14810202e-02,  1.11006936e-02, -7.97877961e-04,  1.06822811e-02,\n",
       "        -2.57275794e-02, -2.34340560e-02, -1.76068302e-02,  3.74440886e-02,\n",
       "        -7.64185861e-02, -4.72622402e-02, -3.27572264e-02, -7.18569336e-03,\n",
       "        -4.53085825e-02,  4.06783409e-02, -1.70751419e-02,  3.52567644e-03,\n",
       "         4.42164298e-03,  1.49106421e-03,  3.68176512e-02,  2.31745262e-02,\n",
       "        -2.79525053e-02,  5.68876825e-02,  1.02578728e-02,  2.06507407e-02,\n",
       "        -1.54372416e-02, -2.24641282e-02,  1.94130912e-02,  8.84840917e-03,\n",
       "         3.99252400e-02,  7.77886435e-02, -2.38020793e-02,  7.14737251e-02,\n",
       "        -1.00755775e-02, -1.08494991e-02,  1.78617835e-02,  2.33523566e-02,\n",
       "        -5.17380871e-02, -3.77948303e-03, -2.61190739e-02,  1.47430124e-02,\n",
       "         1.29183242e-03, -7.94031005e-03,  1.03188874e-02, -5.02168573e-02,\n",
       "        -1.10685537e-02,  2.92008277e-02, -4.55097072e-02, -6.17507584e-02,\n",
       "        -5.01007959e-02, -3.19400541e-02,  3.56948748e-02, -3.29649448e-02,\n",
       "        -2.08451916e-02, -8.41174927e-03, -8.45198333e-03,  1.97558459e-02,\n",
       "         1.75184570e-02, -5.55997491e-02, -1.28370905e-02, -3.12190689e-03,\n",
       "         1.49003742e-02, -1.17948595e-02,  4.48351242e-02, -2.55915429e-02,\n",
       "         4.90458086e-02, -2.55757128e-03, -1.89134441e-02,  3.80496942e-02,\n",
       "        -4.56058644e-02,  8.28830246e-03, -6.04795525e-03, -6.15014620e-02,\n",
       "        -1.04682976e-02, -2.22253036e-02, -7.94931203e-02,  1.00403382e-02,\n",
       "         5.95424101e-02, -4.18819338e-02,  7.33771734e-03, -2.86843292e-02,\n",
       "         1.30296045e-03, -6.89497888e-02, -2.83591934e-02,  5.79134887e-03,\n",
       "         3.40576135e-02,  8.78306385e-03,  3.57467122e-03, -4.11857627e-02,\n",
       "        -2.78929789e-02, -8.72807670e-03,  4.13259976e-02, -1.59994680e-02,\n",
       "        -8.08922108e-03, -3.20716836e-02, -4.38989839e-03, -4.60192189e-03,\n",
       "         3.12835760e-02,  2.70411354e-02,  6.15953002e-03,  4.89444062e-02,\n",
       "         2.85610952e-07,  3.17465951e-04,  2.96480325e-03,  7.97642861e-04,\n",
       "        -8.53873193e-02, -1.12006990e-02,  6.90978020e-03,  4.60343771e-02,\n",
       "        -3.09937280e-02, -5.70020713e-02, -2.13520441e-04,  1.58192459e-02,\n",
       "        -6.90226629e-02,  2.67768209e-03,  1.01097478e-02,  7.05996975e-02,\n",
       "         4.68579307e-03,  5.22019863e-02, -4.89753298e-02,  1.88349746e-02,\n",
       "        -2.68263333e-02, -3.91778462e-02, -4.75329719e-02, -6.58264235e-02,\n",
       "        -6.83627150e-04, -6.86893910e-02, -2.00280435e-02,  2.77797040e-02,\n",
       "        -3.19516994e-02,  6.69076592e-02,  1.30915269e-02,  2.04993356e-02,\n",
       "        -9.98120289e-03,  2.52219718e-02,  2.48376429e-02, -2.19197702e-02,\n",
       "        -5.82621433e-05,  2.09554806e-02,  3.51148732e-02, -1.84655981e-03,\n",
       "         2.23089270e-02, -4.03341502e-02, -1.05464626e-02, -6.97745522e-03,\n",
       "        -4.89751389e-03, -4.20797728e-02, -3.75690050e-02, -5.53467264e-03,\n",
       "        -1.39227612e-02,  3.71150523e-02, -2.15042233e-02, -6.70337379e-02,\n",
       "         3.31932716e-02, -1.80221032e-02,  3.10805291e-02, -2.36989418e-03,\n",
       "         2.99424175e-02,  1.85485370e-02,  5.75076975e-02,  4.83018868e-02,\n",
       "         1.89176982e-03, -7.74479983e-03,  4.14553704e-03, -4.65450529e-03,\n",
       "        -2.11403589e-03,  4.39929292e-02,  8.85788873e-02, -2.53147725e-03,\n",
       "         2.09605382e-34, -5.73769584e-03, -3.41718867e-02,  8.44105030e-04,\n",
       "        -1.45265907e-02, -5.25104702e-02,  2.84898933e-02, -9.34369490e-02,\n",
       "         7.84413831e-04,  7.05511635e-03, -5.20309247e-02, -3.24149504e-02])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_and_chunks[42]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511e7efd",
   "metadata": {},
   "source": [
    "We can clearly see the sentence chunk!! Our semantic search has clearly succeeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcfa5911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: torch.Size([168000, 768])\n",
      "Time take to get scores on 168000 embeddings: 0.03545 seconds.\n"
     ]
    }
   ],
   "source": [
    "larger_embeddings = torch.randn(100*embeddings.shape[0], 768).to(device)\n",
    "print(f\"Embeddings shape: {larger_embeddings.shape}\")\n",
    "\n",
    "# Perform dot product across 168,000 embeddings\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=larger_embeddings)[0]\n",
    "end_time = timer()\n",
    "\n",
    "print(f\"Time take to get scores on {len(larger_embeddings)} embeddings: {end_time-start_time:.5f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ecd0d",
   "metadata": {},
   "source": [
    "Wow. That's quick!\n",
    "\n",
    "That means we can get pretty far by just storing our embeddings in `torch.tensor` for now.\n",
    "\n",
    "However, for *much* larger datasets, we'd likely look at a dedicated vector database/indexing libraries such as Faiss.\n",
    "\n",
    "Let's check the results of our original similarity search.\n",
    "\n",
    "`torch.topk` returns a tuple of values (scores) and indicies for those scores.\n",
    "\n",
    "The indicies relate to which indicies in the `embeddings` tensor have what scores in relation to the query embedding (higher is better).\n",
    "\n",
    "We can use those indicies to map back to our text chunks.\n",
    "\n",
    "First, we'll define a small helper function to print out wrapped text (so it doesn't print a whole text chunk as a single line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee0c5746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper function to print wrapped text \n",
    "import textwrap\n",
    "\n",
    "def print_wrapped(text, wrap_length=80):\n",
    "    wrapped_text = textwrap.fill(text, wrap_length)\n",
    "    print(wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e374407",
   "metadata": {},
   "source": [
    "*Now* we can loop through the `top_results_dot_product` tuple and match up the scores and indicies and then use those indicies to index on our `pages_and_chunks` variable to get the relevant text chunk.\n",
    "\n",
    "Sounds like a lot but we can do it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e92cd61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'macronutrients function'\n",
      "\n",
      "Results:\n",
      "Score: 0.7085\n",
      "Text:\n",
      "Macronutrients Nutrients that are needed in large amounts are called\n",
      "macronutrients. There are three classes of macronutrients: carbohydrates,\n",
      "lipids, and proteins. These can be metabolically processed into cellular energy.\n",
      "The energy from macronutrients comes from their chemical bonds. This chemical\n",
      "energy is converted into cellular energy that is then utilized to perform work,\n",
      "allowing our bodies to conduct their basic functions. A unit of measurement of\n",
      "food energy is the calorie. On nutrition food labels the amount given for\n",
      "“calories” is actually equivalent to each calorie multiplied by one thousand. A\n",
      "kilocalorie (one thousand calories, denoted with a small “c”) is synonymous with\n",
      "the “Calorie” (with a capital “C”) on nutrition food labels. Water is also a\n",
      "macronutrient in the sense that you require a large amount of it, but unlike the\n",
      "other macronutrients, it does not yield calories. Carbohydrates Carbohydrates\n",
      "are molecules composed of carbon, hydrogen, and oxygen.\n",
      "Page number: 5\n",
      "\n",
      "\n",
      "Score: 0.6669\n",
      "Text:\n",
      "Water There is one other nutrient that we must have in large quantities: water.\n",
      "Water does not contain carbon, but is composed of two hydrogens and one oxygen\n",
      "per molecule of water. More than 60 percent of your total body weight is water.\n",
      "Without it, nothing could be transported in or out of the body, chemical\n",
      "reactions would not occur, organs would not be cushioned, and body temperature\n",
      "would fluctuate widely. On average, an adult consumes just over two liters of\n",
      "water per day from food and drink combined. Since water is so critical for\n",
      "life’s basic processes, the amount of water input and output is supremely\n",
      "important, a topic we will explore in detail in Chapter 4. Micronutrients\n",
      "Micronutrients are nutrients required by the body in lesser amounts, but are\n",
      "still essential for carrying out bodily functions. Micronutrients include all\n",
      "the essential minerals and vitamins. There are sixteen essential minerals and\n",
      "thirteen vitamins (See Table 1.1 “Minerals and Their Major Functions” and Table\n",
      "1.2 “Vitamins and Their Major Functions” for a complete list and their major\n",
      "functions). In contrast to carbohydrates, lipids, and proteins, micronutrients\n",
      "are not sources of energy (calories), but they assist in the process as\n",
      "cofactors or components of enzymes (i.e., coenzymes).\n",
      "Page number: 8\n",
      "\n",
      "\n",
      "Score: 0.6496\n",
      "Text:\n",
      "Learning Objectives By the end of this chapter, you will be able to: • Describe\n",
      "basic concepts in nutrition • Describe factors that affect your nutritional\n",
      "needs • Describe the importance of research and scientific methods to\n",
      "understanding nutrition What are Nutrients? The foods we eat contain nutrients.\n",
      "Nutrients are substances required by the body to perform its basic functions.\n",
      "Nutrients must be obtained from our diet, since the human body does not\n",
      "synthesize or produce them. Nutrients have one or more of three basic functions:\n",
      "they provide energy, contribute to body structure, and/or regulate chemical\n",
      "processes in the body. These basic functions allow us to detect and respond to\n",
      "environmental surroundings, move, excrete wastes, respire (breathe), grow, and\n",
      "reproduce. There are six classes of nutrients required for the body to function\n",
      "and maintain overall health. These are carbohydrates, lipids, proteins, water,\n",
      "vitamins, and minerals. Foods also contain non-nutrients that may be harmful\n",
      "(such as natural toxins common in plant foods and additives like some dyes and\n",
      "preservatives) or beneficial (such as antioxidants). 4 | Introduction\n",
      "Page number: 4\n",
      "\n",
      "\n",
      "Score: 0.6391\n",
      "Text:\n",
      "Figure 1.1 The Macronutrie nts: Carbohydrat es, Lipids, Protein, and Water\n",
      "Proteins Proteins are macromolecules composed of chains of subunits called amino\n",
      "acids. Amino acids are simple subunits composed of carbon, oxygen, hydrogen, and\n",
      "nitrogen. Food sources of proteins include meats, dairy products, seafood, and a\n",
      "variety of different plant- based foods, most notably soy. The word protein\n",
      "comes from a Greek word meaning “of primary importance,” which is an apt\n",
      "description of these macronutrients; they are also known colloquially as the\n",
      "“workhorses” of life. Proteins provide four kilocalories of energy per gram;\n",
      "however providing energy is not protein’s most important function. Proteins\n",
      "provide structure to bones, muscles and skin, and play a role in conducting most\n",
      "of the chemical reactions that take place in the body. Scientists estimate that\n",
      "greater than one-hundred thousand different proteins exist within the human\n",
      "body. The genetic codes in DNA are basically protein recipes that determine the\n",
      "order in which 20 different amino acids are bound together to make thousands of\n",
      "specific proteins. Figure 1.1 The Macronutrients: Carbohydrates, Lipids,\n",
      "Protein, and Water Introduction | 7\n",
      "Page number: 7\n",
      "\n",
      "\n",
      "Score: 0.6130\n",
      "Text:\n",
      "Vitamins Major Functions Water-soluble Thiamin (B1) Coenzyme, energy metabolism\n",
      "assistance Riboflavin (B2 ) Coenzyme, energy metabolism assistance Niacin (B3)\n",
      "Coenzyme, energy metabolism assistance Pantothenic acid (B5) Coenzyme, energy\n",
      "metabolism assistance Pyridoxine (B6) Coenzyme, amino acid synthesis assistance\n",
      "Biotin (B7) Coenzyme, amino acid and fatty acid metabolism Folate (B9) Coenzyme,\n",
      "essential for growth Cobalamin (B12) Coenzyme, red blood cell synthesis C\n",
      "(ascorbic acid) Collagen synthesis, antioxidant Fat-soluble A Vision,\n",
      "reproduction, immune system function D Bone and teeth health maintenance, immune\n",
      "system function E Antioxidant, cell membrane protection K Bone and teeth health\n",
      "maintenance, blood clotting Vitamin deficiencies can cause severe health\n",
      "problems and even death. For example, a deficiency in niacin causes a disease\n",
      "called pellagra, which was common in the early twentieth century in some parts\n",
      "of America. The common signs and symptoms of pellagra are known as the\n",
      "“4D’s—diarrhea, dermatitis, dementia, and death.” Until scientists found out\n",
      "that better diets relieved the signs and symptoms of pellagra, many people with\n",
      "the disease ended up hospitalized in insane asylums awaiting death. Other\n",
      "vitamins were also found to prevent certain disorders and diseases such as\n",
      "scurvy (vitamin C), night blindness vitamin A, and rickets (vitamin D). Table\n",
      "1.3 Functions of Nutrients Introduction | 11\n",
      "Page number: 11\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: '{query}'\\n\")\n",
    "print(\"Results:\")\n",
    "# Loop through zipped together scores and indicies from torch.topk\n",
    "for score, idx in zip(top_results_dot_product[0], top_results_dot_product[1]):\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    # Print relevant sentence chunk (since the scores are in descending order, the most relevant chunk will be first)\n",
    "    print(\"Text:\")\n",
    "    print_wrapped(pages_and_chunks[idx][\"sentence_chunk\"])\n",
    "    # Print the page number too so we can reference the textbook further (and check the results)\n",
    "    print(f\"Page number: {pages_and_chunks[idx]['page_number']}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1284a3ae",
   "metadata": {},
   "source": [
    "The first result looks to have nailed it!\n",
    "\n",
    "We get a very relevant answer to our query `\"macronutrients functions\"` even though its quite vague.\n",
    "\n",
    "That's the power of semantic search!\n",
    "\n",
    "And even better, if we wanted to inspect the result further, we get the page number where the text appears.\n",
    "\n",
    "How about we check the page to verify?\n",
    "\n",
    "We can do so by loading the page number containing the highest result (page 5 but really page 5 + 41 since our PDF page numbers start on page 41)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f00840",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m doc.close()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Convert the Pixmap to a numpy array\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m img_array = \u001b[43mnp\u001b[49m.frombuffer(img.samples_mv, \n\u001b[32m     17\u001b[39m                           dtype=np.uint8).reshape((img.h, img.w, img.n))\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Display the image using Matplotlib\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import fitz\n",
    "\n",
    "# Open PDF and load target page\n",
    "pdf_path = \"human-nutrition-text.pdf\" # requires PDF to be downloaded\n",
    "doc = fitz.open(pdf_path)\n",
    "idx = top_results_dot_product[0]['scores']\n",
    "page = doc.load_page(idx + 41) # number of page (our doc starts page numbers on page 41)\n",
    "\n",
    "# Get the image of the page\n",
    "img = page.get_pixmap(dpi=300)\n",
    "\n",
    "# Optional: save the image\n",
    "#img.save(\"output_filename.png\")\n",
    "doc.close()\n",
    "\n",
    "# Convert the Pixmap to a numpy array\n",
    "img_array = np.frombuffer(img.samples_mv, \n",
    "                          dtype=np.uint8).reshape((img.h, img.w, img.n))\n",
    "\n",
    "# Display the image using Matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(13, 10))\n",
    "plt.imshow(img_array)\n",
    "plt.title(f\"Query: '{query}' | Most relevant page:\")\n",
    "plt.axis('off') # Turn off axis\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d2f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
